{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHW4PfK_tKs4",
        "outputId": "e4645d54-525b-4c1c-b52e-848460b044ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into '6GSmartRRM'...\n",
            "remote: Enumerating objects: 108, done.\u001b[K\n",
            "remote: Counting objects: 100% (108/108), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 108 (delta 46), reused 80 (delta 26), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (108/108), 431.25 KiB | 18.75 MiB/s, done.\n",
            "Resolving deltas: 100% (46/46), done.\n"
          ]
        }
      ],
      "source": [
        "COLAB: bool = True\n",
        "if COLAB:\n",
        "  !git clone https://github.com/RubenCid35/6GSmartRRM\n",
        "  !mv 6GSmartRRM/* .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yiUAh6llKD_n"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "O2mAPEEgs4Bd",
        "outputId": "280e1340-7dfa-4dbf-84dc-126cbfcb0c88"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrubencid001\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Simulation Parameters: \n",
              "\n",
              "|                      name |                     value |\n",
              "---------------------------------------------------------\n",
              "|        num_of_subnetworks |                   20.0000 |\n",
              "|              n_subchannel |                    4.0000 |\n",
              "|             deploy_length |                   20.0000 |\n",
              "|             subnet_radius |                    1.0000 |\n",
              "|                      minD |                    0.8000 |\n",
              "|               minDistance |                    2.0000 |\n",
              "|                 bandwidth |             40000000.0000 |\n",
              "|              ch_bandwidth |             10000000.0000 |\n",
              "|                        fc |           6000000000.0000 |\n",
              "|                    lambdA |                    0.0500 |\n",
              "|                  clutType |                     dense |\n",
              "|                  clutSize |                    2.0000 |\n",
              "|                  clutDens |                    0.6000 |\n",
              "|                   shadStd |                    7.2000 |\n",
              "|                 max_power |                    0.0000 |\n",
              "|                    no_dbm |                 -174.0000 |\n",
              "|           noise_figure_db |                    5.0000 |\n",
              "|               noise_power |                    0.0000 |\n",
              "|       correlationDistance |                    5.0000 |\n",
              "|            transmit_power |                    0.0010 |\n",
              "---------------------------------------------------------"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# simple data manipulation\n",
        "import numpy  as np\n",
        "import pandas as pd\n",
        "\n",
        "# deep learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lrs\n",
        "from   torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "# results logging\n",
        "import wandb\n",
        "wandb.login()\n",
        "\n",
        "# progress bar\n",
        "from   tqdm.notebook import tqdm, trange\n",
        "\n",
        "# remove warnings (remove deprecated warnings)\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "# visualization of resultsa\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from   matplotlib.ticker import MaxNLocator\n",
        "import seaborn           as sns\n",
        "\n",
        "# Graph Algorithms.\n",
        "import networkx as nx\n",
        "\n",
        "# Google Colab (many lines are removed)\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "from distutils.dir_util import copy_tree\n",
        "\n",
        "# wheter we are using colab or not\n",
        "if not COLAB and not os.path.exists('./data/simulations'):\n",
        "    os.chdir('..')\n",
        "\n",
        "# Simulation Settings\n",
        "from g6smart.sim_config import SimConfig\n",
        "from g6smart.evaluation import rate_torch as rate_metrics\n",
        "\n",
        "config = SimConfig(0)\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a4RFox2hs4Be"
      },
      "outputs": [],
      "source": [
        "def setup_wandb(name: str, group: str, config: dict[str, float], id: str = None):\n",
        "    config['name'] = name\n",
        "    return wandb.init(\n",
        "        project=\"6GSmartRRM\",\n",
        "        name   = name,\n",
        "        id     = id,\n",
        "        group  = group,\n",
        "        config = config,\n",
        "        resume = \"allow\" if id is None else \"must\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTRBs_8Is4Bf"
      },
      "source": [
        "## Simulations and Information\n",
        "\n",
        "Thanks to the given scripts, we can load a group of generated simulations. They don't have any solutions (neither approximations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAHxSAoFs4Bg",
        "outputId": "2eb20381-0a2f-4aeb-8f94-2d7892236a1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Name of the already simulated data: \n",
            "\n",
            " ----> simulations-200K-sisa.zip\n"
          ]
        }
      ],
      "source": [
        "# Moung Google Drive Code\n",
        "if COLAB:\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Move Simulations to avoid cluttering the drive folder\n",
        "    if not os.path.exists('/content/simulations'):\n",
        "      os.mkdir('/content/simulations')\n",
        "\n",
        "    if list(os.listdir('/content/simulations')) == []:\n",
        "      copy_tree('/content/drive/MyDrive/TFM/simulations', '/content/simulations')\n",
        "\n",
        "    # unzip all simulations\n",
        "    print(\"Name of the already simulated data: \\n\", )\n",
        "    for zip_file in os.listdir('/content/simulations'):\n",
        "        if zip_file.endswith('.zip'):\n",
        "            print(\" ----> \" + zip_file)\n",
        "            with zipfile.ZipFile(\"/content/simulations/\" + zip_file, 'r') as zip_ref:\n",
        "                zip_ref.extractall('/content/simulations/')\n",
        "\n",
        "    SIMULATIONS_PATH: str = \"/content/simulations\"\n",
        "else:\n",
        "    if not os.path.exists('./data/simulations'): os.mkdir('./data/simulations')\n",
        "    for zip_file in os.listdir('data'):\n",
        "        if zip_file.endswith('.zip'):\n",
        "            print(\" ----> \" + zip_file)\n",
        "            with zipfile.ZipFile(\"./data/\" + zip_file, 'r') as zip_ref:\n",
        "                zip_ref.extractall('./data/simulations')\n",
        "    SIMULATIONS_PATH: str = \"./data/simulations\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMKFCdf_s4Bg",
        "outputId": "1a0a6f42-832a-42d4-9b93-950a229e0279"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "channel    matrix shape: 200000 x  4 x 20 x 20 \n",
            "allocation matrix shape: 200000 x 20\n"
          ]
        }
      ],
      "source": [
        "cmg   = np.load(SIMULATIONS_PATH + '/Channel_matrix_gain.npy')\n",
        "sisa_alloc = np.load(SIMULATIONS_PATH + '/sisa-allocation.npy')\n",
        "\n",
        "# get sample from all\n",
        "n_sample = 200_000\n",
        "cmg   = cmg[:n_sample]\n",
        "sisa_alloc = sisa_alloc[:n_sample]\n",
        "\n",
        "n_sample = cmg.shape[0]\n",
        "K, N, _  = cmg.shape[1:]\n",
        "\n",
        "shape    = lambda s: \" x\".join([f\"{d:3d}\" for d in s])\n",
        "print(f\"channel    matrix shape: {shape(cmg.shape)} \\nallocation matrix shape: {shape(sisa_alloc.shape)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4rgJ-N0s4Bh"
      },
      "source": [
        "## Publications to revise\n",
        "\n",
        "* (power) Power control for 6g industrial wireless subnetworks: A graph neural network approach\n",
        "* (allocation) Towards 6g in-x subnetworks with sub-millisecond communication cycles and extreme reliability\n",
        "* (power) Multi-agent deep reinforcement learning for dynamic power allocation in wireless networks\n",
        "* (both) Multi-agent reinforcement learning for dynamic resource management in 6g in-x subnetworks\n",
        "* (both) Multi-agent dynamic resource allocation in 6g in-x subnetworks with limited sensing information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F--fEzMs4Bi"
      },
      "source": [
        "## First Proposal\n",
        "\n",
        "In this proposal, we could mixed different implementations for optimization of problem.\n",
        "We can only consider the following setup:\n",
        "\n",
        "1. Determine a almost optimal subband allocation for the networks. We could use a power selection of $p = p_{max}$\n",
        "2. Based on the obtained allocation, we determine a power control for each subnetwork that minimizes the used\n",
        "power and does not deteriorite the signal.\n",
        "\n",
        "For the subband allocation, we could consider the implementation from this [publication](https://ieeexplore.ieee.org/document/10597067).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7SIFtDfIs4Bi"
      },
      "outputs": [],
      "source": [
        "# First Step: Subband allocation problem\n",
        "class RateConfirmAllocModel(nn.Module):\n",
        "    def __init__(self, n_subnetworks: int, n_bands: int,\n",
        "                 hidden_dim: int = 1000, hidden_layers: int = 4,\n",
        "                 dropout: float | None = 0.01,\n",
        "                 use_weighted: bool = False,\n",
        "                 keep_band_wise: bool = False) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # initialize state\n",
        "        self.n = n_subnetworks\n",
        "        self.k = n_bands\n",
        "\n",
        "        # preprocessing options\n",
        "        self.use_weighted   = use_weighted\n",
        "        self.keep_band_wise = keep_band_wise\n",
        "\n",
        "        # DNN architecture\n",
        "        self.input_size = self.n * self.n if not self.keep_band_wise else self.n * self.n * self.k\n",
        "        self.output_size = self.n * self.k\n",
        "\n",
        "        last_layer = -2 if dropout is None else -3\n",
        "        layers = [nn.BatchNorm1d(self.input_size)] # with batch norm at start\n",
        "        dims = [self.input_size] + [hidden_dim] * (hidden_layers + 1) + [self.output_size]\n",
        "        for i in range(1, len(dims)):\n",
        "            # linear layers with HE initialization\n",
        "            layers.append(nn.Linear(dims[i - 1], dims[i]))\n",
        "            torch.nn.init.kaiming_normal_(layers[-1].weight, nonlinearity='relu')\n",
        "            layers.append(nn.ReLU())\n",
        "\n",
        "            # apply dropout. We have a lot of parameters, it is required\n",
        "            layers.append(nn.BatchNorm1d(dims[i]))\n",
        "            if isinstance(dropout, float):\n",
        "              layers.append(nn.Dropout(dropout))\n",
        "\n",
        "        layers = layers[:last_layer]\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def preprocess(self, channel_gain: np.ndarray | torch.Tensor ) -> torch.Tensor:\n",
        "        channel_gain = torch.tensor(channel_gain, requires_grad=False).float()\n",
        "\n",
        "        if self.keep_band_wise and len(channel_gain.shape[1:]) != 3:\n",
        "            raise ValueError(\"The model expects a channel gain matrix (BxKxNxN)\")\n",
        "\n",
        "        if self.keep_band_wise and self.use_weighted:\n",
        "            # normalize the interference matrix\n",
        "            Hd = torch.diagonal(channel_gain, dim1 = -2, dim2 = -1).unsqueeze(-1)\n",
        "\n",
        "            zero = torch.zeros_like(channel_gain).to(channel_gain.device)\n",
        "            channel_gain = torch.where(Hd > 0, channel_gain / Hd, zero)\n",
        "\n",
        "            # remove self-interference\n",
        "            B, K, N, _ = channel_gain.shape\n",
        "            self_signal = torch.eye(N, device = device).expand(B, K, -1, -1)\n",
        "            channel_gain = channel_gain * (1 - self_signal)\n",
        "\n",
        "        elif not self.keep_band_wise and len(channel_gain.shape[1:]) == 3:\n",
        "            channel_gain = torch.mean(channel_gain, dim = 1)\n",
        "\n",
        "        # flatten the channel information\n",
        "        channel_gain = channel_gain.flatten(start_dim=1)\n",
        "\n",
        "        # transform to dbm scale to restrict value range\n",
        "        channel_gain = 10 * torch.log10(channel_gain + 1e-9) # transform to Dbm\n",
        "\n",
        "        # normalize to values.\n",
        "        # cavg = channel_gain.mean(dim = 1, keepdim = True)\n",
        "        # cstd = channel_gain.std( dim = 1, keepdim = True)\n",
        "        # channel_gain = (channel_gain - cavg) / cstd\n",
        "        return channel_gain\n",
        "\n",
        "    def forward(self, channel_gain: torch.Tensor, t: float = 1.0 ) -> torch.Tensor:\n",
        "        # preprocess to obtain a NxN channel gain\n",
        "        channel_gain = self.preprocess(channel_gain)\n",
        "        # apply model\n",
        "        channel_network = self.model(channel_gain)\n",
        "        # determine best allocation\n",
        "        channel_network = channel_network.reshape(-1, self.k, self.n)\n",
        "        # derive probabilities\n",
        "        return F.softmax(channel_network / t, dim = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEiBBXrys4Bj"
      },
      "source": [
        "The used loss function in the first-stage correspond to modified version of:\n",
        "\n",
        "$$ \\sum \\mathbb{E}(\\hat{R} > R^{REQ}) $$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LbIFu3a4s4Bj"
      },
      "outputs": [],
      "source": [
        "def loss_fullfield_req(config: SimConfig, C: torch.Tensor, A: torch.Tensor, req: float, mode: str = 'mean') -> torch.Tensor:\n",
        "    # calculate shannon rate\n",
        "    sinr = rate_metrics.signal_interference_ratio(config, C, A, None)\n",
        "    rate = torch.sum(A * torch.log2(1 + sinr), dim = 1)\n",
        "\n",
        "    rate = F.sigmoid(req - rate) / req\n",
        "    rate = torch.sum(rate, dim=1)\n",
        "    return rate\n",
        "\n",
        "def min_approx(x: torch.Tensor, p: float = 1e2):\n",
        "    \"\"\"\n",
        "    Differentiable Approximation of Minimum Function. This function approximates\n",
        "    the value of min(x)\n",
        "\n",
        "      # based on fC https://mathoverflow.net/questions/35191/a-differentiable-approximation-to-the-minimum-function\n",
        "    \"\"\"\n",
        "    mu = 0\n",
        "    inner = torch.mean(torch.exp(- p * (x - mu)), dim = 1)\n",
        "    return mu - (1 / p) * torch.log(inner)\n",
        "\n",
        "def loss_pure_rate(config: SimConfig, C: torch.Tensor, A: torch.Tensor, mode: str = 'sum', p: int = 10) -> torch.Tensor:\n",
        "    sinr = rate_metrics.signal_interference_ratio(config, C, A, None)\n",
        "    rate = torch.sum(A * torch.log2(1 + sinr), dim = 1)\n",
        "\n",
        "    if mode == 'sum':\n",
        "      loss_rate = torch.sum(rate, dim = 1)\n",
        "    elif mode == 'min':\n",
        "      loss_rate = min_approx(rate, p)\n",
        "    elif mode == 'max':\n",
        "      loss_rate = torch.sum(rate, dim = 1)\n",
        "    return - loss_rate\n",
        "\n",
        "class TemperatureScheduler:\n",
        "    def __init__(self, tinit=1.0, gamma=0.99, tmin = 1e-10):\n",
        "        self.tinit = tinit\n",
        "        self.gamma = gamma\n",
        "        self.tmin  = tmin\n",
        "        self.step_count = 0\n",
        "\n",
        "    def step(self):\n",
        "        \"\"\"Increases tau based on an exponential schedule.\"\"\"\n",
        "        temp = self.tinit * self.gamma ** self.step_count\n",
        "        self.step_count += 1\n",
        "        return max(temp, self.tmin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eQ7OzEmGuZ9v"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "def real_time_plot(*metrics):\n",
        "    assert len(metrics) % 2 == 0, \"A odd pair of metrics is required\"\n",
        "    clear_output(wait=True)  # Clear the previous plot\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(14, 4))  # Two subplots, stacked vertically\n",
        "    # Plot loss\n",
        "    for i, loss in enumerate(metrics[:len(metrics) // 2]):\n",
        "      ax[0].plot(loss, label = f\"loss: {i}\")\n",
        "    ax[0].set_title('Real-Time Loss')\n",
        "    ax[0].set_xlabel('Epochs')\n",
        "    ax[0].set_ylabel('Loss')\n",
        "    ax[0].legend()\n",
        "\n",
        "    # Plot metric (e.g., SINR or accuracy)\n",
        "    for i, metric in enumerate(metrics[len(metrics) // 2:]):\n",
        "      ax[1].plot(metric, label = f\"metric: {i}\")\n",
        "    ax[1].set_title('Real-Time Metric')\n",
        "    ax[1].set_xlabel('Epochs')\n",
        "    ax[1].set_ylabel('Bit Rate (Mbps)')\n",
        "    ax[1].legend()\n",
        "\n",
        "    plt.tight_layout()  # Adjust layout to avoid overlap\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Z9ak0CcPu2i1"
      },
      "outputs": [],
      "source": [
        "def binarization_error(alloc: torch.Tensor) -> float:\n",
        "    rounded = torch.round(alloc)\n",
        "    return torch.mean(torch.abs(alloc - rounded))\n",
        "\n",
        "def update_metrics(metrics, A, C, config, req):\n",
        "    A    = rate_metrics.onehot_allocation(A, 4, 20)\n",
        "    sinr = rate_metrics.signal_interference_ratio(config, C, A, None)\n",
        "    rate = rate_metrics.bit_rate(config, sinr, A)\n",
        "    fairness = rate_metrics.jain_fairness(rate)\n",
        "    spectral = rate_metrics.spectral_efficency(config, rate)\n",
        "    plf      = rate_metrics.proportional_loss_factor(config, C, A, None)\n",
        "\n",
        "    shannon  = torch.sum(A * torch.log2(1 + sinr), dim = 1)\n",
        "    ecf_req  = torch.mean((shannon >= req).float(), dim = 1)\n",
        "\n",
        "    metrics['bit-rate'] += rate.mean().item() / 1e6\n",
        "    metrics['jain-fairness'] += fairness.mean().item()\n",
        "    metrics['spectral-efficency'] += spectral.mean().item()\n",
        "    metrics['proportional-loss' ] += plf.mean().item()\n",
        "    metrics['over-requirement' ] += ecf_req.mean().item()\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "29JxMoLsxXUo"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE: int = 1024\n",
        "\n",
        "# build datasets\n",
        "TRAIN_SAMPLE: int = 150_000\n",
        "VALID_SAMPLE: int =  50_000\n",
        "\n",
        "#TESTS_SAMPLE: int =   0_000\n",
        "whole_data = TensorDataset(torch.tensor(cmg).float())\n",
        "train_data, valid_data = random_split(\n",
        "    whole_data,\n",
        "    [TRAIN_SAMPLE, VALID_SAMPLE], # , TESTS_SAMPLE\n",
        "    torch.Generator().manual_seed(101)\n",
        ")\n",
        "\n",
        "train_data = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle = True)\n",
        "valid_data = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle = True)\n",
        "# tests_data = DataLoader(tests_data, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cl2Xj5FQs4Bk"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE: int = 1024\n",
        "MAX_EPOCH : int = 200\n",
        "LR: float  = 1e-4\n",
        "\n",
        "# under ideal conditions, the sisa ideal shannon rate is around 4.\n",
        "REQ: float      = 8.\n",
        "\n",
        "learning_config = {\n",
        "    'loss': 'pure-min-rate',\n",
        "    'max-epoch': MAX_EPOCH,\n",
        "    'batch-size': BATCH_SIZE,\n",
        "    'learning-rate': LR,\n",
        "    'desired-norm-rate' : REQ,\n",
        "    'train-valid-split' : f\"{TRAIN_SAMPLE}-{VALID_SAMPLE}\"\n",
        "}\n",
        "\n",
        "# training config\n",
        "HS: int    = 1024\n",
        "HL: int    = 6\n",
        "DP: float  = 0.1\n",
        "KEEP_BANDS: bool = True\n",
        "WEIGHTED_GAIN: bool = True\n",
        "\n",
        "model_config = {\n",
        "    'hidden-dim': HS,\n",
        "    'hidden-layers': HL,\n",
        "    'keep-bands': KEEP_BANDS,\n",
        "    'weighted-gain': WEIGHTED_GAIN,\n",
        "}\n",
        "\n",
        "name  = \"p1-alloc-dnn-03-00-base\"\n",
        "training_config = {}\n",
        "training_config.update(model_config)\n",
        "training_config.update(learning_config)\n",
        "\n",
        "try: wandb.finish(quiet = True)\n",
        "except: pass\n",
        "run = setup_wandb(name, 'rate-confirming', training_config, id = None)\n",
        "print(\"run config:\", run.config)\n",
        "\n",
        "model = RateConfirmAllocModel(20, 4, HS, HL, DP, KEEP_BANDS, WEIGHTED_GAIN).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), LR, weight_decay=1e-5)\n",
        "scheduler = lrs.CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-6)\n",
        "temp_scheduler = TemperatureScheduler(1.0, 0.98)\n",
        "\n",
        "train_loss, valid_loss, train_rate, valid_rate = [], [], [], []\n",
        "for epoch in trange(MAX_EPOCH, desc = \"training epoch\", unit = \"epoch\"):\n",
        "    real_time_plot(train_loss, valid_loss, train_rate, valid_rate)\n",
        "\n",
        "    # training step\n",
        "    model.train()\n",
        "    training_loss = 0.\n",
        "    train_binary_loss = 0.\n",
        "\n",
        "    temp = 1.0 # temp_scheduler.step()\n",
        "    training_metrics = defaultdict(lambda : 0)\n",
        "    for sample in tqdm(train_data, desc = 'training step:', unit = 'batch', total = len(train_data), leave=False):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        sample     = sample[0].to(device)\n",
        "        alloc_prob = model(sample, temp)\n",
        "        loss       = loss_pure_rate(config, sample, alloc_prob, 'min').mean()\n",
        "        # loss       = loss_fullfield_req(config, sample, alloc_prob, REQ).mean()\n",
        "        training_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        train_binary_loss += binarization_error(alloc_prob).item()\n",
        "        training_metrics = update_metrics(training_metrics, alloc_prob, sample, config, REQ)\n",
        "\n",
        "    scheduler.step()\n",
        "    training_loss = training_loss / len(train_data)\n",
        "    train_binary_loss = train_binary_loss / len(train_data)\n",
        "    training_metrics = { 'train-' + key: val / len(train_data) for key, val in training_metrics.items()}\n",
        "\n",
        "    model.eval()\n",
        "    validation_loss = 0.\n",
        "    valid_binary_loss = 0.\n",
        "    validation_metrics = defaultdict(lambda : 0.)\n",
        "    for sample in tqdm(valid_data, desc = 'validation step:', unit = 'batch', total = len(valid_data), leave = False):\n",
        "        sample     = sample[0].to(device)\n",
        "        alloc_prob = model(sample, temp)\n",
        "        loss       = loss_pure_rate(config, sample, alloc_prob, 'min').mean()\n",
        "        # loss       = loss_fullfield_req(config, sample, alloc_prob, REQ).mean()\n",
        "        validation_loss += loss.item()\n",
        "\n",
        "        valid_binary_loss += binarization_error(alloc_prob).item()\n",
        "        validation_metrics = update_metrics(validation_metrics, alloc_prob, sample, config, REQ)\n",
        "\n",
        "    validation_loss = validation_loss / len(valid_data)\n",
        "    valid_binary_loss = valid_binary_loss / len(valid_data)\n",
        "\n",
        "    validation_metrics = { 'valid-' + key: val / len(valid_data) for key, val in validation_metrics.items()}\n",
        "\n",
        "    logged_values = {\n",
        "        'train-loss': training_loss, 'valid-loss': validation_loss, 'temperature': temp,\n",
        "        'train-binary-loss': train_binary_loss, 'valid-binary-loss': valid_binary_loss\n",
        "    }\n",
        "\n",
        "    logged_values.update(training_metrics)\n",
        "    logged_values.update(validation_metrics)\n",
        "\n",
        "    train_loss.append(training_loss)\n",
        "    valid_loss.append(validation_loss)\n",
        "    train_rate.append(training_metrics['train-bit-rate'])\n",
        "    valid_rate.append(validation_metrics['valid-bit-rate'])\n",
        "    wandb.log(logged_values)\n",
        "\n",
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvifQXKKRuil",
        "outputId": "f8138a13-e117-4b33-92e3-4d3579d8a271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([40000, 20]) torch.Size([40000, 4, 20, 20]) torch.Size([40000, 4, 20])\n",
            "defaultdict(<function <lambda> at 0x7c4c905bfec0>, {'bit-rate': 44.04659837538272, 'jain-fairness': 0.9330245348655138, 'spectral-efficency': 4.404659837538271, 'proportional-loss': 0.9426409830170853, 'over-requirement': 0.08009874820709229})\n",
            "defaultdict(<function <lambda> at 0x7c4c905bfec0>, {'bit-rate': 44.6684386388895, 'jain-fairness': 0.9417886232713405, 'spectral-efficency': 4.466843863888949, 'proportional-loss': 0.8873354604566845, 'over-requirement': 0.08583875000476837})\n"
          ]
        }
      ],
      "source": [
        "sisa_tensor = torch.tensor(sisa_alloc[-40_000:]).type(torch.int64).to(device)\n",
        "data_tensor = torch.tensor(cmg[-40_000:]).to(device)\n",
        "allc_tensor = model(data_tensor).to(device)\n",
        "\n",
        "print(sisa_tensor.shape, data_tensor.shape, allc_tensor.shape)\n",
        "print(update_metrics(defaultdict(lambda : 0), sisa_tensor, data_tensor, config, 6))\n",
        "print(update_metrics(defaultdict(lambda : 0), allc_tensor, data_tensor, config, 6))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
