{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vhZSH0IMiPUh",
    "outputId": "139f020a-34de-4049-d21f-f22bae72aa96"
   },
   "outputs": [],
   "source": [
    "COLAB: bool = True\n",
    "if COLAB:\n",
    "  !git clone https://github.com/RubenCid35/6GSmartRRM\n",
    "  !mv 6GSmartRRM/* .\n",
    "  !pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7_4rZYBicaw"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JIZ_Z94dXzZf"
   },
   "outputs": [],
   "source": [
    "%pip install -q torch_geometric\n",
    "%pip install -q pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.6.0+cu124.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gkMLQjGDidK4",
    "outputId": "b80ff497-9f3f-41bc-9de5-b5e47bc2b218"
   },
   "outputs": [],
   "source": [
    "# simple data manipulation\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import numpy.typing as npt\n",
    "\n",
    "# deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lrs\n",
    "from   torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# results logging\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "# progress bar\n",
    "from   tqdm.notebook import tqdm, trange\n",
    "\n",
    "# remove warnings (remove deprecated warnings)\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# visualization of resultsa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from   matplotlib.ticker import MaxNLocator\n",
    "import seaborn           as sns\n",
    "\n",
    "# Graph Algorithms.\n",
    "import networkx as nx\n",
    "\n",
    "# Google Colab (many lines are removed)\n",
    "import os\n",
    "import zipfile\n",
    "from google.colab import drive\n",
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "# wheter we are using colab or not\n",
    "if not COLAB and not os.path.exists('./data/simulations'):\n",
    "    os.chdir('..')\n",
    "\n",
    "# Simulation Settings\n",
    "from g6smart.sim_config import SimConfig\n",
    "from g6smart.evaluation import rate_torch as rate_metrics\n",
    "from g6smart.baseline.subband.sisa import sisa_algoritm\n",
    "config = SimConfig(0)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2bHBI6yXie1k"
   },
   "outputs": [],
   "source": [
    "def setup_wandb(name: str, group: str, config: dict[str, float], id: str = None):\n",
    "    config['name'] = name\n",
    "    return wandb.init(\n",
    "        project=\"6GSmartRRM\",\n",
    "        name   = name,\n",
    "        id     = id,\n",
    "        group  = group,\n",
    "        config = config,\n",
    "        resume = \"allow\" if id is None else \"must\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTRBs_8Is4Bf"
   },
   "source": [
    "## Simulations and Information\n",
    "\n",
    "Thanks to the given scripts, we can load a group of generated simulations. They don't have any solutions (neither approximations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AAHxSAoFs4Bg",
    "outputId": "5281dc10-d581-4c6d-92a1-df2eedb0f63f"
   },
   "outputs": [],
   "source": [
    "# Moung Google Drive Code\n",
    "if COLAB:\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Move Simulations to avoid cluttering the drive folder\n",
    "    if not os.path.exists('/content/simulations'):\n",
    "      os.mkdir('/content/simulations')\n",
    "\n",
    "    print(\"simulations folder:\", list(os.listdir('/content/simulations')))\n",
    "    if len(os.listdir('/content/simulations')) == 0:\n",
    "      copy_tree('/content/drive/MyDrive/TFM/simulations', '/content/simulations')\n",
    "\n",
    "    # unzip all simulations\n",
    "    print(\"Name of the already simulated data: \\n\", )\n",
    "    for zip_file in os.listdir('/content/simulations'):\n",
    "        if zip_file.endswith('.zip'):\n",
    "            print(\" ----> \" + zip_file)\n",
    "            with zipfile.ZipFile(\"/content/simulations/\" + zip_file, 'r') as zip_ref:\n",
    "                zip_ref.extractall('/content/simulations/')\n",
    "\n",
    "    SIMULATIONS_PATH: str = \"/content/simulations\"\n",
    "    MODELS_PATH: str = \"/content/drive/MyDrive/TFM/models/\"\n",
    "else:\n",
    "    if not os.path.exists('./data/simulations'): os.mkdir('./data/simulations')\n",
    "    for zip_file in os.listdir('data'):\n",
    "        if zip_file.endswith('.zip'):\n",
    "            print(\" ----> \" + zip_file)\n",
    "            with zipfile.ZipFile(\"./data/\" + zip_file, 'r') as zip_ref:\n",
    "                zip_ref.extractall('./data/simulations')\n",
    "    SIMULATIONS_PATH: str = \"./data/simulations\"\n",
    "    MODELS_PATH: str = \"./models/\"\n",
    "    if not os.path.exists(MODELS_PATH):\n",
    "      os.mkdir(MODELS_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nMKFCdf_s4Bg",
    "outputId": "da34ceb8-9f70-4364-a3dc-84ba9959d123"
   },
   "outputs": [],
   "source": [
    "cmg   = np.load(SIMULATIONS_PATH + '/Channel_matrix_gain.npy')\n",
    "sisa_alloc = np.load(SIMULATIONS_PATH + '/sisa-allocation.npy')\n",
    "\n",
    "# get sample from all\n",
    "n_sample = 110_000\n",
    "cmg   = cmg[:n_sample]\n",
    "sisa_alloc = sisa_alloc[:n_sample].astype(int)\n",
    "\n",
    "n_sample = B = cmg.shape[0]\n",
    "K, N, _  = cmg.shape[1:]\n",
    "\n",
    "shape    = lambda s: \" x\".join([f\"{d:3d}\" for d in s])\n",
    "print(f\"channel    matrix shape: {shape(cmg.shape)} \\nallocation matrix shape: {shape(sisa_alloc.shape)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aah3-XbPY-qF"
   },
   "outputs": [],
   "source": [
    "def metrics(C, A, P):\n",
    "  C = torch.tensor(C)\n",
    "  A = torch.tensor(A)\n",
    "  P = torch.tensor(P) if P is not None else None\n",
    "  A    = rate_metrics.onehot_allocation(A, 4, 20)\n",
    "  sinr = rate_metrics.signal_interference_ratio(config, C, A, P)\n",
    "  shannon  = torch.sum(A * torch.log2(1 + sinr), dim = 1).numpy()\n",
    "  return float(shannon.mean()), float(shannon.min()), float(shannon.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E68FMQWeLoeo"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "\n",
    "# === CONFIG ===\n",
    "BATCH_SIZE: int = 512\n",
    "TRAIN_SAMPLE: int = 65_000\n",
    "VALID_SAMPLE: int = 25_000\n",
    "TESTS_SAMPLE: int = 20_000\n",
    "\n",
    "# === Convert numpy arrays to tensors ===\n",
    "whole_data       = torch.tensor(cmg).float()                  # [total_samples, K, N, N]\n",
    "sisa_data        = torch.tensor(sisa_alloc).long()            # [total_samples, N]\n",
    "power_data       = torch.full_like(sisa_data, config.transmit_power, dtype = torch.float32)\n",
    "\n",
    "# === Create data splits ===\n",
    "train_idx, valid_idx, tests_idx = random_split(\n",
    "    range(len(whole_data)),\n",
    "    [TRAIN_SAMPLE, VALID_SAMPLE, TESTS_SAMPLE],\n",
    "    generator=torch.Generator().manual_seed(101)\n",
    ")\n",
    "\n",
    "# === Slice tensors ===\n",
    "train_cmg   = whole_data[train_idx]\n",
    "valid_cmg   = whole_data[valid_idx]\n",
    "tests_cmg   = whole_data[tests_idx]\n",
    "\n",
    "train_sisa  = sisa_data[train_idx]\n",
    "valid_sisa  = sisa_data[valid_idx]\n",
    "tests_sisa  = sisa_data[tests_idx]\n",
    "\n",
    "train_power = power_data[train_idx]\n",
    "valid_power = power_data[valid_idx]\n",
    "tests_power = power_data[tests_idx]\n",
    "\n",
    "# === Create PyTorch Datasets ===\n",
    "train_dataset = TensorDataset(train_cmg, train_sisa, train_power)\n",
    "valid_dataset = TensorDataset(valid_cmg, valid_sisa, valid_power)\n",
    "tests_dataset = TensorDataset(tests_cmg, tests_sisa, tests_power)\n",
    "\n",
    "# === Wrap in DataLoaders ===\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "tests_loader = DataLoader(tests_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_-bHR-SZBdF"
   },
   "source": [
    "# Joint Allocation: Graph Neural Network\n",
    "\n",
    "This section implements the following paper:\n",
    "* Graph Neural Networks Approach for\n",
    "Joint Wireless Power Control and\n",
    "Spectrum Allocation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svwzuIpRZUhA"
   },
   "source": [
    "## Graph Representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AAJriE37Zaxm"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from typing import List, Tuple\n",
    "def transform2graphs(cmg: torch.Tensor) ->  List[Data]:\n",
    "  B, K, N, _ = cmg.shape\n",
    "\n",
    "  # precompute all node features\n",
    "  node_feats = cmg.diagonal(dim1 = 2, dim2 = 3).unsqueeze(-1)\n",
    "\n",
    "  # create edge indices for all graphs\n",
    "  rows = torch.arange(N).repeat_interleave(N-1)\n",
    "  cols = torch.cat([\n",
    "      torch.cat([\n",
    "          torch.arange(0, i),\n",
    "          torch.arange(i+1, N)\n",
    "      ])\n",
    "      for i in range(N)\n",
    "  ])\n",
    "\n",
    "  edge_index = torch.stack([cols, rows], dim = 0)\n",
    "\n",
    "  # mask self signal\n",
    "  mask = ~torch.eye(N, dtype=torch.bool, device=cmg.device)\n",
    "  mask = mask.reshape(1, 1, N, N).expand(B, K, -1, -1)\n",
    "  edge_attrs = cmg[mask].view(B, K, -1, 1)\n",
    "\n",
    "  graphs = []\n",
    "  for b in range(B):\n",
    "      batch_graphs = []\n",
    "      for k in range(K):\n",
    "          graph = Data(\n",
    "              x=node_feats[b, k],\n",
    "              edge_index=edge_index.clone(),\n",
    "              edge_attr=edge_attrs[b, k]\n",
    "          )\n",
    "          batch_graphs.append(graph)\n",
    "      graphs.append(batch_graphs)\n",
    "\n",
    "  return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd5ikP-PduSD",
    "outputId": "733e74b9-2c02-4747-916e-2248e3541f32"
   },
   "outputs": [],
   "source": [
    "g = torch.tensor(cmg[[0, 1]]).float()\n",
    "print(\"channel state matrix:\", g.shape)\n",
    "graphs = transform2graphs(g)\n",
    "print(\"nº of samples:\", len(graphs), \"\\nnª of subgraphs:\", len(graphs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCHuH1JT2YDC"
   },
   "source": [
    "## Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaHFA7Cd2XXK"
   },
   "outputs": [],
   "source": [
    "from torch.nn import Linear, Parameter\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "class MLP(nn.Module):\n",
    "  def __init__(\n",
    "      self, input_size: int, output_size: int,\n",
    "      hidden_layers: int, hidden_dim: int,\n",
    "      normalize: bool = False, dropout: float | None = None\n",
    "    ):\n",
    "    super().__init__()\n",
    "\n",
    "    layers = []\n",
    "    dims   = [input_size] + [hidden_dim] * (hidden_layers) + [output_size]\n",
    "    for _in, _out in zip(dims[:-1], dims[1:]):\n",
    "      layers.append(nn.Linear(_in, _out))\n",
    "      layers.append(nn.ReLU())\n",
    "      if normalize: layers.append(nn.BatchNorm1d(_out))\n",
    "      if isinstance(dropout, float) and 0 < dropout < 1:\n",
    "        layers.append(nn.Dropout(dropout))\n",
    "\n",
    "    avoid_layers = int(normalize) + int(isinstance(dropout, float) and 0 < dropout < 1)\n",
    "    if avoid_layers > 1:\n",
    "      layers = layers[:-avoid_layers]\n",
    "    self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "  def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "    return self.mlp(X)\n",
    "\n",
    "\n",
    "class GNNExtractor(MessagePassing):\n",
    "  def __init__(\n",
    "      self, node_dim: int, edge_dim: int,\n",
    "      hidden_layers: int, hidden_dim: int,\n",
    "      normalize: bool = False, dropout: float | None = None\n",
    "    ):\n",
    "    super().__init__(aggr='max')\n",
    "    self.mlp_msg = MLP(\n",
    "      node_dim + edge_dim  , hidden_dim, hidden_layers, hidden_dim,\n",
    "      normalize = normalize, dropout = dropout\n",
    "    )\n",
    "    self.mlp_upd = MLP(\n",
    "      node_dim + hidden_dim, hidden_dim, hidden_layers, hidden_dim,\n",
    "      normalize = normalize, dropout = dropout\n",
    ")\n",
    "\n",
    "  def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_attr: torch.Tensor) -> torch.Tensor:\n",
    "      return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "  def message(self, x_j: torch.Tensor, edge_attr: torch.Tensor) -> torch.Tensor:\n",
    "      return self.mlp_msg(torch.cat([x_j, edge_attr], dim=1))\n",
    "\n",
    "  def update(self, aggr_out: torch.Tensor, x: torch.Tensor) -> torch.Tensor:\n",
    "      return self.mlp_upd(torch.cat([x, aggr_out], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LUu9TIxB8UeS"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "class GNNEncoder(nn.Module):\n",
    "  def __init__(\n",
    "    self,node_dim: int, edge_dim: int,\n",
    "    hidden_dim: int, hidden_layers: int, num_layers: int,\n",
    "    normalize: bool = False, dropout: float | None = None,\n",
    "  ):\n",
    "    super().__init__()\n",
    "    self.layers = nn.ModuleList([\n",
    "        GNNExtractor(\n",
    "            node_dim if i == 0 else hidden_dim,\n",
    "            edge_dim,\n",
    "            hidden_layers,\n",
    "            hidden_dim,\n",
    "            normalize=normalize,\n",
    "            dropout=dropout,\n",
    "        ) for i in range(num_layers)\n",
    "    ])\n",
    "\n",
    "  def forward(self, graphs: List[List[Data]]) -> torch.Tensor:\n",
    "    data_list = [g for batch in graphs for g in batch]\n",
    "    batch_obj = Batch.from_data_list(data_list)\n",
    "\n",
    "    # Process all graphs simultaneously\n",
    "    x = batch_obj.x\n",
    "    for layer in self.layers:\n",
    "        x = layer(x, batch_obj.edge_index, batch_obj.edge_attr)\n",
    "\n",
    "    # Reshape back to original structure (B, N, K, D)\n",
    "    B = len(graphs)\n",
    "    K = len(graphs[0])\n",
    "    N = x.size(0) // (B * K)  # Original number of nodes\n",
    "    D = x.size(-1)\n",
    "\n",
    "    # Reshape: (B*K*N, D) -> (B, K, N, D) -> (B, N, K, D)\n",
    "    return x.view(B, K, N, D).transpose(1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WdDcDdw8SBO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import softmax\n",
    "\n",
    "class EGATLayer(MessagePassing):\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_dim: int,\n",
    "        edge_dim: int,\n",
    "        out_dim: int,\n",
    "        heads: int = 1,\n",
    "        dropout: float = 0.0,\n",
    "        negative_slope: float = 0.2,\n",
    "    ):\n",
    "        super().__init__(aggr='add', node_dim=0)\n",
    "        self.node_dim = node_dim\n",
    "        self.edge_dim = edge_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.heads = heads\n",
    "        self.neg_slope = negative_slope\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Linear transformations for nodes and edges\n",
    "        self.lin_node = nn.Linear(node_dim, heads * out_dim, bias=False)\n",
    "        self.lin_edge = nn.Linear(edge_dim, heads * out_dim, bias=False)\n",
    "\n",
    "        # Attention logit parameters (for nodes + edges)\n",
    "        self.attn_src = nn.Parameter(torch.Tensor(1, heads, out_dim))\n",
    "        self.attn_dst = nn.Parameter(torch.Tensor(1, heads, out_dim))\n",
    "        self.attn_edge = nn.Parameter(torch.Tensor(1, heads, out_dim))\n",
    "\n",
    "        # Final bias and output projection\n",
    "        self.bias = nn.Parameter(torch.Tensor(heads * out_dim))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.lin_node.weight)\n",
    "        nn.init.xavier_uniform_(self.lin_edge.weight)\n",
    "        nn.init.xavier_uniform_(self.attn_src)\n",
    "        nn.init.xavier_uniform_(self.attn_dst)\n",
    "        nn.init.xavier_uniform_(self.attn_edge)\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor) -> Tensor:\n",
    "        # Project nodes and edges into multi-head space\n",
    "        x_proj = self.lin_node(x).view(-1, self.heads, self.out_dim)\n",
    "        edge_proj = self.lin_edge(edge_attr).view(-1, self.heads, self.out_dim)\n",
    "\n",
    "        # Propagate messages (calls message() and aggregate())\n",
    "        out = self.propagate(\n",
    "            edge_index,\n",
    "            x=x_proj,\n",
    "            edge_attr=edge_proj,\n",
    "        )\n",
    "\n",
    "        # Combine heads and add bias\n",
    "        out = out.view(-1, self.heads * self.out_dim) + self.bias\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor, index: Tensor) -> Tensor:\n",
    "        # Compute attention scores using both node and edge features\n",
    "        alpha_src = (x_j * self.attn_src).sum(-1)\n",
    "        alpha_dst = (x_i * self.attn_dst).sum(-1)\n",
    "        alpha_edge = (edge_attr * self.attn_edge).sum(-1)\n",
    "\n",
    "        alpha = alpha_src + alpha_dst + alpha_edge\n",
    "        alpha = F.leaky_relu(alpha, self.neg_slope)\n",
    "        alpha = softmax(alpha, index)  # Normalize attention weights\n",
    "\n",
    "        # Apply dropout to attention weights\n",
    "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "\n",
    "        # Weight messages by attention\n",
    "        return x_j * alpha.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LMjja6X68bIn"
   },
   "outputs": [],
   "source": [
    "class GNNEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_dim: int,\n",
    "        edge_dim: int,\n",
    "        hidden_dim: int,\n",
    "        hidden_layers: int,\n",
    "        num_layers: int,\n",
    "        heads: int = 1,\n",
    "        dropout: float | None = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            EGATLayer(\n",
    "                node_dim if i == 0 else hidden_dim * heads,\n",
    "                edge_dim,\n",
    "                hidden_dim,\n",
    "                heads=heads,\n",
    "                dropout=dropout if dropout else 0.0,\n",
    "            )\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, graphs: List[List[Data]]) -> torch.Tensor:\n",
    "        data_list = [g for batch in graphs for g in batch]\n",
    "        batch_obj = Batch.from_data_list(data_list)\n",
    "\n",
    "        x = batch_obj.x\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, batch_obj.edge_index, batch_obj.edge_attr)\n",
    "\n",
    "        B = len(graphs)\n",
    "        K = len(graphs[0])\n",
    "        N = x.size(0) // (B * K)\n",
    "        D = x.size(-1)\n",
    "\n",
    "        return x.view(B, K, N, D).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DdTBfpVI6uYH"
   },
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, mid_channels: List[int]):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for out_channels in mid_channels:\n",
    "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            in_channels = out_channels\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        # z: (B, N, K, D)\n",
    "        z = z.permute(0, 3, 1, 2)  # → (B, D, N, K)\n",
    "        x = self.conv(z)           # → (B, 1, N, K) after final channel = 1\n",
    "        return x.squeeze(1)        # → (B, N, K)\n",
    "\n",
    "class AllocationHead(nn.Module):\n",
    "    def __init__(self, embed_dim: int, K: int, p_max: float):\n",
    "        super().__init__()\n",
    "        self.cnn = CNNBlock(embed_dim, [8, 4, 1])\n",
    "        self.p_max = p_max\n",
    "\n",
    "    def forward(self, Z: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Z: (B, N, K, D)\n",
    "        X = self.cnn(Z)                      # (B, N, K)\n",
    "        channel_probs = F.softmax(X, dim=-1)   # (B, N, K)\n",
    "        channel_probs = channel_probs.permute(0, 2, 1)\n",
    "        power = F.sigmoid(X).mean(dim=-1) * self.p_max  # (B, N)\n",
    "        return channel_probs, power\n",
    "\n",
    "\n",
    "class GNNJointResourceModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, gnn_args: dict, head_args: dict,\n",
    "    ):\n",
    "      super().__init__()\n",
    "      self.encoder = GNNEncoder(**gnn_args)\n",
    "      self.head = AllocationHead(**head_args)\n",
    "\n",
    "    def forward(self, graphs: List[List[Data]]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "      Z = self.encoder(graphs)\n",
    "      return self.head(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1IlVFC6gHZ_"
   },
   "outputs": [],
   "source": [
    "HIDDEN_DIM: int = 10\n",
    "encoder_args = dict(\n",
    "  node_dim=1, edge_dim=1, hidden_dim=HIDDEN_DIM, num_layers=3,\n",
    "  hidden_layers=1, dropout=None\n",
    ")\n",
    "alloc_args = dict(embed_dim=HIDDEN_DIM, K=4, p_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "id": "ygFo3cYPAAgv",
    "outputId": "259c41d3-56d6-43b8-a735-2a16e8e804e7"
   },
   "outputs": [],
   "source": [
    "g = torch.tensor(cmg[[0, 1]]).float()\n",
    "print(\"channel state matrix:\", g.shape)\n",
    "graphs = transform2graphs(g)\n",
    "print(\"nº of samples:\", len(graphs), \"\\nnª of subgraphs:\", len(graphs[0]))\n",
    "model = GNNJointResourceModel(encoder_args, alloc_args)\n",
    "channel, power = model(graphs)\n",
    "print(\"power alloc:\", power.shape)\n",
    "print(\"channel alloc:\", channel.shape)\n",
    "\n",
    "print(\"graph 1 & node 1:\")\n",
    "print(\"power: \", power[0, 0])\n",
    "print(\"power: \", channel[0, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K846ofe5FpKj"
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uKD5K52BK7Iv"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "def real_time_plot(*metrics):\n",
    "    names = ['training', 'validation']\n",
    "    assert len(metrics) % 2 == 0, \"A odd pair of metrics is required\"\n",
    "    clear_output(wait=True)  # Clear the previous plot\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 4))  # Two subplots, stacked vertically\n",
    "    # Plot loss\n",
    "    for i, loss in enumerate(metrics[:len(metrics) // 2]):\n",
    "      ax[0].plot(loss, label = f\"loss: {names[i]}\")\n",
    "    ax[0].set_title('Real-Time Loss')\n",
    "    ax[0].set_xlabel('Epochs')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Plot metric (e.g., SINR or accuracy)\n",
    "    for i, metric in enumerate(metrics[len(metrics) // 2:]):\n",
    "      ax[1].plot(metric, label = f\"loss: {names[i]}\")\n",
    "    ax[1].set_title('Real-Time Metric')\n",
    "    ax[1].set_xlabel('Epochs')\n",
    "    ax[1].set_ylabel('Bit Rate (Mbps)')\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to avoid overlap\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dTunHO2UHL7Y"
   },
   "outputs": [],
   "source": [
    "def supervised_loss_from_targets(\n",
    "    channel_probs: torch.Tensor,      # [B, N, K]\n",
    "    sisa_alloc: torch.Tensor,         # [B, N] → integers in [0, K-1]\n",
    "    pred_power: torch.Tensor,         # [B, N]\n",
    "    power_alloc_max: torch.Tensor     # [B, N]\n",
    ") -> torch.Tensor:\n",
    "    cce = nn.CrossEntropyLoss()\n",
    "    mse = nn.MSELoss()\n",
    "\n",
    "    # reshape to 2D for batch processing\n",
    "    L1 = cce(channel_probs.view(-1, channel_probs.size(-1)), sisa_alloc.view(-1))\n",
    "    L2 = mse(pred_power, power_alloc_max)\n",
    "    return L1 + L2\n",
    "\n",
    "def min_approx(x: torch.Tensor, p: float = 1e2):\n",
    "    \"\"\"\n",
    "    Differentiable Approximation of Minimum Function. This function approximates\n",
    "    the value of min(x)\n",
    "\n",
    "      # based on fC https://mathoverflow.net/questions/35191/a-differentiable-approximation-to-the-minimum-function\n",
    "    \"\"\"\n",
    "    mu = 0\n",
    "    inner = torch.mean(torch.exp(- p * (x - mu)), dim = 1)\n",
    "    return mu - (1 / p) * torch.log(inner)\n",
    "\n",
    "def base_loss( rate: torch.Tensor, mode: str = 'sum', p: int = 10 ) -> torch.Tensor:\n",
    "    if mode == 'sum':\n",
    "      loss_rate = torch.sum(rate, dim = 1)\n",
    "    elif mode == 'min':\n",
    "      loss_rate = min_approx(rate, p)\n",
    "    elif mode == 'mean':\n",
    "      loss_rate = torch.mean(rate, dim = 1)\n",
    "    return - loss_rate\n",
    "\n",
    "def requirement_loss( rate: torch.Tensor, req: float = 1 ):\n",
    "  # in ideal conditions, this is equal to the spectral efficiency as all\n",
    "  # subbands have the bandwidth.\n",
    "  return F.relu(req - rate).mean(dim = 1)\n",
    "\n",
    "def joint_loss(\n",
    "    config: SimConfig, C: torch.Tensor, A: torch.Tensor, P: torch.Tensor,\n",
    "    req: float = 1., violation_penality: float = 1.\n",
    "):\n",
    "\n",
    "  A    = rate_metrics.onehot_allocation(A, 4, 20)\n",
    "  sinr = rate_metrics.signal_interference_ratio(config, C, A, P)\n",
    "  rate = torch.sum(A * torch.log2(1 + sinr), dim = 1)\n",
    "  base = base_loss(rate, mode = \"min\", p = 10)\n",
    "  reqs = requirement_loss(rate, req = req)\n",
    "  return base + violation_penality * reqs, base, reqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QmAw-o9iFsy8"
   },
   "outputs": [],
   "source": [
    "def binarization_error(alloc: torch.Tensor) -> float:\n",
    "    rounded = torch.round(alloc)\n",
    "    return torch.mean(torch.abs(alloc - rounded))\n",
    "\n",
    "def update_metrics(metrics, A, C, P, config, req):\n",
    "    A    = rate_metrics.onehot_allocation(A, 4, 20)\n",
    "    sinr = rate_metrics.signal_interference_ratio(config, C, A, P, False)\n",
    "    rate = rate_metrics.bit_rate(config, sinr, A)\n",
    "    fairness = rate_metrics.jain_fairness(rate)\n",
    "    spectral = rate_metrics.spectral_efficency(config, rate)\n",
    "    plf      = rate_metrics.proportional_loss_factor(config, C, A, P)\n",
    "\n",
    "    shannon  = torch.sum(A * torch.log2(1 + sinr), dim = 1)\n",
    "    ecf_req  = torch.mean((shannon >= req).float(), dim = 1)\n",
    "\n",
    "    metrics['bit-rate'] += rate.mean().item() / 1e6\n",
    "    metrics['jain-fairness'] += fairness.mean().item()\n",
    "    metrics['spectral-efficency'] += spectral.mean().item()\n",
    "    metrics['proportional-loss' ] += plf.mean().item()\n",
    "    metrics['over-requirement' ] += ecf_req.mean().item()\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 498,
     "referenced_widgets": [
      "c1e5deb84c0643bfa1bc6fece4d427e8",
      "eb16c370c0f3470ea23fffe8211be527",
      "e4ab2aeced8c4ce58ea572264819027b",
      "f86e2bacf2cf42bd9ed73993f119a5ce",
      "1fe59d40628f48bc89e1208e5fefede0",
      "0edc5454378d4b60ab3ade665fe10ed7",
      "ca700812af9a444ca0d24fcf51af8e7b",
      "b979bcf4d0d94875a50e5748c3deb264",
      "9731dd97736e4e87ababb6d1f95dcbbc",
      "adaaedd4286d496482ca9af663dabfe5",
      "5cc4fae45dc74ce8a3a6528d7be0c53b",
      "35b244109aef43e995b0282315271956",
      "06ed3fe29d574ebd81dfecdf9a3f325f",
      "7a15250fc0464964ae3adc497a3f7d2c",
      "8f4d04da5e9b4bfcaec0c9d57cf3c111",
      "d92cc7a7e1bc480188e04705524b4fe8",
      "02e25f4e129a4d2281c3e9722d61ccac",
      "c5e638d09de14c849bb94c8ecb800c29",
      "854b78ba85814e958011fdb217b5fb51",
      "09f1b8bdedf34116aee838136f72e855",
      "6529347a214b4e1baa21a921bdb89307",
      "29bc844649f547fbbe19940079415922",
      "133eb6a747ac4d02919f89563e769bb2",
      "7c697a33866d48cb9a38a5c6121dbd23",
      "471f550c3b944d759e83763f1ecf0d18",
      "f00e3f8719ab4453b502766cb73c5f74",
      "a5eb12d6014b43429efc5222e0d18de1",
      "5bb29818d1ac42229667338d22483f7d",
      "7908a7ce5fec4f8983fb8b4f0eeb2e12",
      "8b548d1baca44ad39ab22f378566952a",
      "cbb4d33b51474676851122aa6834cebb",
      "037a5a3f48094bf486d3f9d75bd864df",
      "55c85826772b4e20b79e3d7952788d3b",
      "f1213e75de3e415696a420671d1da58f",
      "295f895f217a46d99c30d171db9cd727",
      "6fb4c871cd4c4fa68d440d4502fe976b",
      "62cee5ceff814a56859493a573619bbd",
      "71b6f7979eb84b36b6a02336358ddc0a",
      "daeee5cd5605497ab101ab2853d465a0",
      "b628ee2ce65a4c3e843cfbee90e50a83",
      "31c7d3f21bf94a009c3af531a6421a09",
      "09194d541c894a8b841c31a5956be8db",
      "da12986c95124dd7bae3f9d972429b07",
      "bf3500ee95bb4a6b9a9e41967da5eb7b",
      "90054bc13a4a48f1b4ef5ba88bfc0bff",
      "80491169b9504f0285e0470829b2bd73",
      "f47f329f287c44cfb2dd0468dd9c2454",
      "cb1b7778352342f1a810f013ec774439",
      "3ae5582633694ac09960684e8d8fcf69",
      "39b72c8b48774c23b757c4b7f2942050",
      "9d5f2b3faeb14b0c99bee022e8bb4f88",
      "25ea10520ea4418089d343c471910059",
      "cd9d79cf514746d28b4233764fa3cf8a",
      "4cf175177c124cd28a925461c3018041",
      "f378225cd2004f93a0153a4458bbf9b5",
      "ce168891f9f34090a5c50b973f996856",
      "fe3295e1e8984a7a8e6fd38db6ee6717",
      "0df0b4df9ddf4519909cca0430a5aca1",
      "c29bffaa2f834e959ffb20437d10ca81",
      "648d0c5aa534494b9d5ab7a43e450fef",
      "0986816c7a204a819fdbc21a38298f04",
      "a1a41c2eede24bbbaa0405c02e1e8b6b",
      "f0f04f3140cb43a6ae505e4f973887f9",
      "77d5f10502c34a3aa4999efa6284eaca",
      "df265b8bb09148ff847cc43df55616e6",
      "f5c49a4724c34380929a65a4cbcec619",
      "a3fe9cc42b7e4afdac97640d3babfc1d",
      "9622bda2a04d4de6b6f6d3d3ca0167dd",
      "90a620fb9ed54a429f94562bcfcc8687",
      "83a0529db14a41d3b322f43c5e1a5635",
      "28392fb35e6b4f49a2510826c9e0097d",
      "499a1d6778954aa4b4440b4044951a54",
      "af06f6fda02e42be9fed5deb2ebf48eb",
      "7d05a00b31fb461688af6d75dbc683a2",
      "99a52bbb6c374ad0a3efaeb02ef3ef98",
      "f84de332cae8417196518e896d505579",
      "22d9d4cd71614512aa87fff2b14b1c95",
      "f7ebd9604b2a4d0e98335a861737082f",
      "f171b68757d54f638dba4a642c8017ff",
      "3cf56b6edc974efeaa807b2d3111fa26",
      "323aec4845ad4d379c6184ba276d09ad",
      "325e6e98383642339504d3521a912d65",
      "03fb32b8fe434cc09351ff44971af94e",
      "4b1cb41a9ce341aba91948fe53908a5b",
      "1930615c4c1b4916ad1ce75879f4f0a1",
      "7c40ba38a53544f9983091c152ba9359",
      "f9e6160a4724491db793bff80b52afd6",
      "199bda3b68e94fe4a04ececcb7b918f0",
      "ec4c05d466ce4360a364ec2829e91b60",
      "c6d5fde0ba1242899626ca8124611f6d",
      "2bf5702a24e74d0ca527b378f97a31ee",
      "8f61d3a5dec14e4fac82ae268ff6d03f",
      "4b6322f4aa88477b90ee04cc8d7a285c",
      "5249fdfd0b0249889d7228432a375607",
      "0f0fb7b7b835498ea509879685a95c96",
      "cb4c9429b5ef47cc90a45a58bbc5f82f",
      "67215dff228f4b70b57a4d3da72058f6",
      "cf26676312174a0f906f7ead48dd7fd0",
      "ee4e61fc685b489e9b6e1f760fb90e82",
      "2d4c3aab5cf0468ba6daaaa39eddc9c8",
      "1befb580bcab4ccdb536383e66261776",
      "e8d4cc9291b04e7ab9f99937cf3797ea",
      "933d7d0a63c04246ba39e27593c76ac1",
      "be0894cd26e04e83a6890562edd44e63",
      "7af1bce13f8b4c7582102b40c31a522a",
      "62e4e58aa42348e8bc3789a0602413f8",
      "7777d7f7b2d840aeba5c5f203d879ffe",
      "ece23cf9f8604c869acc2454ee29a661",
      "7835d6abfac9484db429a130b73154ac",
      "a4aba6c270c746f19830dbf63eb62f6e",
      "5eabc552ceb744dd95d8410fca323b21",
      "426eb1e66d894ea0aa3a43bc243b6110",
      "8b339a315fb94be688508c76c6829a9e",
      "e13f55d6a21e4f1d9bd57c5130874ced",
      "91660540b7174060ab76cbc607ecdbcb",
      "669d9697f17d4033a351f7390bccdd47",
      "129bb4c8e1574b99ac53f0eb0925a3d3",
      "77eff7e50267435e88db1b81e7d90081",
      "8d86a1ef5c1c403986c8334c8b53d735",
      "0a7cf3a4c83f473fbd6c51c0be242f64",
      "81dd587e04ea4a34abf10f645a1dae20",
      "c72c7cebd6b349f8b75de85ba18e7761",
      "6a5649fec6a4480e9c69d91a5f7d6336",
      "77797c51007244539660da0bbd4bc6d4",
      "34eb1d4160a14819b67a1057508707c4",
      "7121020bbd0e481c9c2b55cf0862cea0",
      "d91024e3e8a94968a274ab71b5fa7f49",
      "0dd8f86173b14c1792729c9a84ee2151",
      "f956d46fffa14c16806c44f4b94571ce",
      "09b344fae9aa46ebb8cffe7856dddd10",
      "01b78c05826e4a2f9a1ae4a403e0e85c",
      "00a030ecf49647949706a0c2ab66ae58",
      "47fa6a7a61a34ad59e5aa8391db7dfd9",
      "3142bac36e1d4b878f1f75058036d073",
      "9ef2bdb29dbb4b7b9a3258613aa27f09",
      "ba106805ba6e4b5685ae4b0f5fa09a3a",
      "75025530c97341a7b9ee1f07170e06fd",
      "57961a0be0c84e8fbd76f9b2ad391bda",
      "1791267b24c346898934ac7529909094",
      "924b4ced6d264c2397ccfbef2cec12e6",
      "48ab37905694446d8eb8027578bfc5a2",
      "0b78a7f35ba2484ebb9feada297a8823",
      "1f584137975e430b861e94acba3510cc",
      "fa69849dbdb04ac7b4c9c3ba8e60a570",
      "d85a6ed2b3ae47fcad62146674f4723c",
      "deb900ce5af348ba84fae63eb93c1e1b",
      "73a8c706cdea45f6887e5a15eff2f575",
      "1d486343b220411c9ac3ae2e583ff1dc",
      "4c4839c3b0db4bdb99acacaa43782fdd",
      "c0fd9d89e993480f96d6b4a363bc96f9",
      "d3d05c97024d424280e98c432b82c630",
      "0b6e8ca18ae74e1faf5c2bda07a9a059",
      "cf4930fb3a434525b664fb20f7a31dd8",
      "383a345136294f54b0bec3748144dc7e"
     ]
    },
    "id": "2X-Wl9FkFr3C",
    "outputId": "d1c1b24c-2196-4c60-8ecb-8ec421b1c016"
   },
   "outputs": [],
   "source": [
    "MAX_EPOCH : int = 7\n",
    "LR: float  = 1e-1\n",
    "\n",
    "# under ideal conditions, the sisa ideal shannon rate is around 4.\n",
    "REQ: float      = 3.\n",
    "VIOLATION_PENALITY: float = 10.\n",
    "\n",
    "learning_config = {\n",
    "    'loss': 'pure-min-rate',\n",
    "    'max-epoch': MAX_EPOCH,\n",
    "    'batch-size': BATCH_SIZE,\n",
    "    'learning-rate': LR,\n",
    "    'desired-min-rate' : REQ,\n",
    "    'qos-penality': VIOLATION_PENALITY,\n",
    "    'train-valid-split' : f\"{TRAIN_SAMPLE}-{VALID_SAMPLE}\"\n",
    "}\n",
    "\n",
    "# training config\n",
    "HIDDEN_DIM: int = 32\n",
    "encoder_args = dict(\n",
    "  node_dim=1, edge_dim=1, hidden_dim=HIDDEN_DIM, num_layers=3,\n",
    "  hidden_layers=2, normalize=False, dropout=None\n",
    ")\n",
    "alloc_args = dict(embed_dim=HIDDEN_DIM, K=4, p_max=config.transmit_power)\n",
    "\n",
    "\n",
    "name  = \"p1-joint-000-v1\"\n",
    "training_config = {}\n",
    "training_config[\"encoder\"] = encoder_args\n",
    "training_config[\"alloc\"] = alloc_args\n",
    "\n",
    "try: wandb.finish(quiet = True)\n",
    "except: pass\n",
    "run = setup_wandb(name, 'rate-confirming', training_config, id = None)\n",
    "print(\"run config:\", run.config)\n",
    "\n",
    "model = GNNJointResourceModel(encoder_args, alloc_args).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), LR, weight_decay=1e-5)\n",
    "scheduler = lrs.CosineAnnealingLR(optimizer, T_max=30, eta_min=1e-4)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "train_loss, valid_loss, train_rate, valid_rate = [], [], [], []\n",
    "for epoch in trange(MAX_EPOCH, desc = \"training epoch\", unit = \"epoch\"):\n",
    "    real_time_plot(train_loss, valid_loss, train_rate, valid_rate)\n",
    "\n",
    "    # training step\n",
    "    model.train()\n",
    "    training_loss = 0.\n",
    "    train_binary_loss = 0.\n",
    "    train_rate_loss = 0.\n",
    "    train_reqs_loss = 0.\n",
    "\n",
    "    desc = f'training step (epoch: {epoch:03d}):'\n",
    "    training_metrics = defaultdict(lambda : 0)\n",
    "    for sample, sisa_alloc, base_power in tqdm(train_loader, desc = desc, unit = 'batch', total = len(train_loader), leave=False):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        sample = sample.to(device)                          # [B, K, N, N]\n",
    "        # Vectorized graph processing\n",
    "        graphs = transform2graphs(sample)\n",
    "        graphs = [\n",
    "            [g.to(device, non_blocking=True) for g in batch]\n",
    "            for batch in graphs\n",
    "        ]\n",
    "\n",
    "        # Mixed precision\n",
    "        #with torch.cuda.amp.autocast():\n",
    "        alloc_prob, power_alloc = model(graphs)\n",
    "        loss, sub_loss, req_loss = joint_loss(\n",
    "          config = config, C = sample, A = alloc_prob, P = power_alloc,\n",
    "          req = REQ, violation_penality = VIOLATION_PENALITY\n",
    "        )\n",
    "        loss = loss.mean()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        training_loss += loss.item()\n",
    "        train_binary_loss += binarization_error(alloc_prob).item()\n",
    "        train_rate_loss += sub_loss.mean().item()\n",
    "        train_reqs_loss += req_loss.mean().item()\n",
    "        # Update metrics (ensure no GPU retention)\n",
    "        training_metrics = update_metrics(training_metrics, alloc_prob.detach(), sample, power_alloc.detach(), config, REQ)\n",
    "\n",
    "        # Cleanup\n",
    "        del sample, graphs, alloc_prob, power_alloc, loss, sub_loss, req_loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    training_loss = training_loss / len(train_loader)\n",
    "    train_binary_loss = train_binary_loss / len(train_loader)\n",
    "    train_rate_loss   = train_rate_loss / len(train_loader)\n",
    "    train_reqs_loss   = train_reqs_loss / len(train_loader)\n",
    "    training_metrics = { 'train-' + key: val / len(train_loader) for key, val in training_metrics.items()}\n",
    "\n",
    "    # validation step\n",
    "    model.eval()\n",
    "    validation_loss = 0.\n",
    "    valid_binary_loss = 0.\n",
    "    valid_rate_loss = 0.\n",
    "    valid_reqs_loss = 0.\n",
    "\n",
    "    desc = f'validation step (epocch: {epoch:03d}):'\n",
    "    validation_metrics = defaultdict(lambda : 0)\n",
    "    for sample, sisa_alloc, base_power in tqdm(valid_loader, desc = desc, unit = 'batch', total = len(valid_loader), leave=False):\n",
    "        sample = sample.to(device)                          # [B, K, N, N]\n",
    "        graphs = transform2graphs(sample)\n",
    "        graphs = [\n",
    "            [g.to(device, non_blocking=True) for g in batch]\n",
    "            for batch in graphs\n",
    "        ]\n",
    "\n",
    "        # Mixed precision\n",
    "        # with torch.cuda.amp.autocast():\n",
    "        alloc_prob, power_alloc = model(graphs)\n",
    "        loss, sub_loss, req_loss = joint_loss(\n",
    "          config = config, C = sample, A = alloc_prob, P = power_alloc,\n",
    "          req = REQ, violation_penality = VIOLATION_PENALITY\n",
    "        )\n",
    "        loss = loss.mean()\n",
    "\n",
    "        validation_loss   += loss.item()\n",
    "        valid_binary_loss += binarization_error(alloc_prob).item()\n",
    "        valid_rate_loss += sub_loss.mean().item()\n",
    "        valid_reqs_loss += req_loss.mean().item()\n",
    "        # Update metrics (ensure no GPU retention)\n",
    "        validation_metrics = update_metrics(\n",
    "            validation_metrics, alloc_prob.detach(), sample, power_alloc.detach(),\n",
    "            config, REQ\n",
    "        )\n",
    "\n",
    "        # Cleanup\n",
    "        del sample, graphs, alloc_prob, power_alloc, loss, sub_loss, req_loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    validation_loss = validation_loss / len(valid_loader)\n",
    "    valid_binary_loss = valid_binary_loss / len(valid_loader)\n",
    "    valid_rate_loss   = valid_rate_loss / len(valid_loader)\n",
    "    valid_reqs_loss   = valid_reqs_loss / len(valid_loader)\n",
    "    validation_metrics = { 'valid-' + key: val / len(valid_loader) for key, val in validation_metrics.items()}\n",
    "\n",
    "    logged_values = {\n",
    "      'train-loss': training_loss, 'valid-loss': validation_loss,\n",
    "      'train-base-loss': valid_rate_loss, 'valid-base-loss': valid_rate_loss,\n",
    "      'train-violation-loss': train_reqs_loss, 'valid-violation-loss': valid_reqs_loss,\n",
    "      'train-binary-loss': train_binary_loss, 'valid-binary-loss': valid_binary_loss\n",
    "    }\n",
    "\n",
    "    logged_values.update(training_metrics)\n",
    "    logged_values.update(validation_metrics)\n",
    "\n",
    "    train_loss.append(training_loss)\n",
    "    valid_loss.append(validation_loss)\n",
    "    train_rate.append(training_metrics['train-bit-rate'])\n",
    "    valid_rate.append(validation_metrics['valid-bit-rate'])\n",
    "    wandb.log(logged_values)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ngOSV0FuFwRq",
    "outputId": "6442632e-762a-4556-e684-b0136cf7af99"
   },
   "outputs": [],
   "source": [
    "wandb.finish()\n",
    "del sample, graphs, alloc_prob, power_alloc, loss, sub_loss, req_loss\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "21b0607daa534fe998abdf7de17f02a5",
      "2de628549d7644629c228243257b79f6",
      "e23d94a77d314578bcf3dd320a968e7f",
      "81a4627003e34d1095aee2401aa96a3a",
      "722bafddf8e74ff4a23b43d54477911c",
      "53c2d872588b495cbc73d45cc95e688e",
      "ad01b8bf97da4045abb85c00b35d1bda",
      "037098a0aadf4521989c15388ff1d7a7",
      "3a51d7c08d5846d5888ba994a1062903",
      "fae6bb33f1374a0f973a3efeb91f50e4",
      "246212330d394a518da92a0f3858988d"
     ]
    },
    "id": "GDdCtEXgGJ8M",
    "outputId": "30742972-f55f-4953-f33a-11ea349d7cbb"
   },
   "outputs": [],
   "source": [
    "orates = []\n",
    "srates = []\n",
    "\n",
    "model.eval()\n",
    "for sample, sisa_alloc, ploc in tqdm(tests_loader, desc = 'testing step:', unit = 'batch', total = len(tests_loader), leave=False):\n",
    "    sample = sample.to(device)                          # [B, K, N, N]\n",
    "    sisa_alloc = sisa_alloc.to(device)                          # [B, K, N, N]\n",
    "    ploc = ploc.to(device)                          # [B, K, N, N]\n",
    "    graphs = transform2graphs(sample)\n",
    "    graphs = [\n",
    "        [g.to(device, non_blocking=True) for g in batch]\n",
    "        for batch in graphs\n",
    "    ]\n",
    "    alloc_prob, P = model(graphs)\n",
    "    A = torch.argmax(alloc_prob, dim = 1)\n",
    "\n",
    "    A    = rate_metrics.onehot_allocation(A, 4, 20)\n",
    "    sinr = rate_metrics.signal_interference_ratio(config, sample, A.detach(), P.detach())\n",
    "    rate = rate_metrics.bit_rate(config, sinr, A).cpu().numpy()\n",
    "    orates.append(rate / 1e6)\n",
    "\n",
    "    A    = rate_metrics.onehot_allocation(sisa_alloc, 4, 20)\n",
    "    sinr = rate_metrics.signal_interference_ratio(config, sample, sisa_alloc, ploc)\n",
    "    rate = rate_metrics.bit_rate(config, sinr, sisa_alloc).cpu().numpy()\n",
    "    srates.append(rate / 1e6)\n",
    "\n",
    "    del sample, graphs, alloc_prob, P, A, sisa_alloc, ploc\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "orates = np.concat(orates, axis = 0).flatten()\n",
    "srates = np.concat(srates, axis = 0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "9hwckX1Qj6PV",
    "outputId": "c0126814-6602-4d5b-e65d-0f31335cd999"
   },
   "outputs": [],
   "source": [
    "from g6smart import evaluation as evals\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def add_cdf_plot(sample, label, color = None, ax = None, show_legend = True):\n",
    "    ax = ax or plt.gca()\n",
    "\n",
    "    # add CDF\n",
    "    pos, cdf = evals.get_cdf(sample)\n",
    "    ax.plot(pos, cdf, label = label, color = color)\n",
    "\n",
    "    # cdf func\n",
    "    cdf_func = interp1d(pos, cdf, bounds_error=False, fill_value=(0, 1))\n",
    "    # add percentiles\n",
    "    percentiles = [ 0.0005, 0.05, 0.25, 0.50]\n",
    "    qs = np.quantile(sample, percentiles)\n",
    "    styles = ['-', '-.', '--', \":\"]\n",
    "    for s, p, q in zip(styles, percentiles, qs):\n",
    "        ax.plot(\n",
    "            [q, q], [0, float(cdf_func(q))],\n",
    "            linestyle=s, alpha=0.6, color = \"black\",\n",
    "            label=f'Q{p}' if show_legend else None\n",
    "        )\n",
    "\n",
    "plt.figure(figsize = (5.5, 5))\n",
    "\n",
    "rates = np.random.random(size = 500) * 40\n",
    "add_cdf_plot(orates, \"Ours\", \"red\", show_legend=True)\n",
    "add_cdf_plot(srates, \"SISA\", \"blue\", show_legend=False)\n",
    "\n",
    "# Sort legend: group quantiles at the end\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "normal = [(h, l) for h, l in zip(handles, labels) if not l.startswith(\"Q\")]\n",
    "quantiles = [(h, l) for h, l in zip(handles, labels) if l.startswith(\"Q\")]\n",
    "handles, labels = zip(*(normal + quantiles))\n",
    "plt.legend(handles, labels)\n",
    "plt.ylim(bottom=0)\n",
    "plt.xlim(left=0)\n",
    "plt.xlabel(\"Bit Rate (Mbps)\")\n",
    "plt.ylabel(\"CDF\")\n",
    "plt.title(\"Bit Rate's CDF\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pDeReMew4S0t"
   },
   "outputs": [],
   "source": [
    "BASE = \"/content/drive/MyDrive/TFM/results\"\n",
    "np.save(BASE + \"/test-ours.npy\", orates)\n",
    "np.save(BASE + \"/test-sisa.npy\", srates)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
