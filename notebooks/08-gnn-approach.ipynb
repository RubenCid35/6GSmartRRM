{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "938bb266",
    "outputId": "7647fcf5-5538-4a00-a4b2-0051ccc7718e"
   },
   "outputs": [],
   "source": [
    "COLAB: bool = False\n",
    "if COLAB:\n",
    "  !git clone https://github.com/RubenCid35/6GSmartRRM\n",
    "  !mv 6GSmartRRM/* /content/\n",
    "  !pip install -e .\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8cddfa8",
    "outputId": "1303944c-5d30-4b5f-9121-cdcb464a6c6d"
   },
   "outputs": [],
   "source": [
    "# vast ai check gpu for invalid specs\n",
    "!nvidia-smi -q | grep 'Power Limit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6fd41596",
    "outputId": "b0b5b158-a82c-4220-ac87-cba185c53752"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "!pip install -q wandb matplotlib seaborn\n",
    "!pip install -q torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "58617b46",
    "outputId": "ca0d75d0-c59c-4093-fb6b-831e38259e76"
   },
   "outputs": [],
   "source": [
    "# simple data manipulation\n",
    "import numpy  as np\n",
    "\n",
    "# deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lrs\n",
    "import torch.cuda.amp as amp # For Automatic Mixed Precision\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Data, Dataset as GeoDataset, Batch\n",
    "from torch_geometric.loader import DataLoader # Import PyG DataLoader\n",
    "import torch_geometric.nn as gnn\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# progress bar\n",
    "from   tqdm.notebook import tqdm, trange\n",
    "# import wandb\n",
    "\n",
    "# remove warnings (remove deprecated warnings)\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# visualization of resultsa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from   matplotlib.ticker import MaxNLocator\n",
    "import seaborn           as sns\n",
    "\n",
    "# wheter we are using colab or not\n",
    "import os\n",
    "if not COLAB and not os.path.exists('./data/simulations'):\n",
    "    os.chdir('..')\n",
    "    print(\"current path: \", os.getcwd())\n",
    "\n",
    "# Simulation Settings\n",
    "from g6smart.sim_config import SimConfig\n",
    "from g6smart.evaluation import rate as rate\n",
    "from g6smart.evaluation.utils import get_cdf\n",
    "from g6smart.evaluation import rate_torch as rate_metrics\n",
    "from g6smart.proposals  import loss as loss_funcs, rate_cnn, rate_dnn\n",
    "from g6smart.data import load_data, create_datasets, download_simulations_data\n",
    "# from g6smart.track import setup_wandb, real_time_plot\n",
    "from g6smart.train import train_model\n",
    "\n",
    "config = SimConfig(0)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "b7f01ff1"
   },
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "827720f9",
    "outputId": "a1a89517-0d1b-448a-e8b6-5dbbfe9d9036"
   },
   "outputs": [],
   "source": [
    "simulation_path, models_path = download_simulations_data(COLAB)\n",
    "print(\"simulations data paths:\", simulation_path)\n",
    "print(\"saved model location  :\", models_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "id": "354cc5ea"
   },
   "outputs": [],
   "source": [
    "csi_data = load_data(simulation_path, n_samples= 120_000)\n",
    "train_dataset, valid_dataset, tests_dataset = create_datasets(\n",
    "#    csi_data, split_sizes=[130_000, 60_000, 10_000], seed=101\n",
    "    csi_data, split_sizes=[ 70_000, 30_000, 20_000], seed=101\n",
    "#    csi_data, split_sizes=[ 7_000, 3_000, 2_000], seed=101\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "id": "24970054"
   },
   "source": [
    "## Graph Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bf748bb6",
    "outputId": "8b6a693c-a130-41de-b18f-080a6989f7cd"
   },
   "outputs": [],
   "source": [
    "class CustomGraphDataset(GeoDataset):\n",
    "    def __init__(self, torch_dataset: Dataset, remove_edges: int | None = None):\n",
    "        super().__init__(None, None)\n",
    "        self.torch_dataset = torch_dataset\n",
    "        self.remove_edges  = remove_edges\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self): return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self): return []\n",
    "\n",
    "    def len(self) -> int: return len(self.torch_dataset)\n",
    "    def __len__(self) -> int: return len(self.torch_dataset)\n",
    "\n",
    "    def get(self, idx: int) -> Data:\n",
    "        # get raw data\n",
    "        csi_tensor = self.torch_dataset[idx][0]\n",
    "        K, N, _ = csi_tensor.shape\n",
    "\n",
    "        # node features\n",
    "        # self signal\n",
    "        diagonal    = torch.arange(N)\n",
    "        self_gain   = csi_tensor[:, diagonal, diagonal].permute(1, 0)\n",
    "\n",
    "        # optimization features\n",
    "        band_alloc  = torch.ones((N, K)) / K\n",
    "        x           = band_alloc\n",
    "\n",
    "        # edage features\n",
    "\n",
    "\n",
    "\n",
    "        row, col    = torch.combinations(torch.arange(N), 2).t()\n",
    "        edge_index  = torch.cat(\n",
    "            [torch.stack([row, col]), torch.stack([col, row])],\n",
    "            dim = 1\n",
    "        )\n",
    "        edge_attr1   = csi_tensor[:, row, col].permute(1, 0)\n",
    "        edge_attr2   = csi_tensor[:, col, row].permute(1, 0)\n",
    "        edge_attr    = torch.cat([edge_attr1, edge_attr2], dim = 0)\n",
    "        if self.remove_edges is not None and self.remove_edges > 0:\n",
    "            num_edges = edge_attr1.shape[0]\n",
    "            if self.remove_edges >= num_edges:\n",
    "                # If removing all or more edges than available, return empty edges\n",
    "                edge_index = torch.empty((2, 0), dtype=torch.long, device=edge_index.device)\n",
    "                edge_attr = torch.empty((0, K), dtype=torch.float, device=edge_attr.device)\n",
    "            else:\n",
    "                mean_attr = torch.mean(edge_attr, dim = 1)\n",
    "                sorted_index = torch.argsort(mean_attr, descending = False)\n",
    "                sorted_index = sorted_index[self.remove_edges:]\n",
    "                edge_index   = edge_index[:, sorted_index]\n",
    "                edge_attr    = edge_attr[sorted_index, :]\n",
    "\n",
    "        data = Data(\n",
    "            x = band_alloc, v = self_gain,\n",
    "            edge_index = edge_index, edge_attr = edge_attr\n",
    "        )\n",
    "\n",
    "        return csi_tensor, data\n",
    "\n",
    "dataset = CustomGraphDataset(tests_dataset, 50)\n",
    "dataset[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "id": "b70b35dd"
   },
   "source": [
    "## Graph Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "id": "c254e9e6"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "class EdgeAwareMPNN(gnn.MessagePassing):\n",
    "    def __init__(self, in_channels, edge_dim, out_channels, aggr='add'):\n",
    "        super().__init__(aggr=aggr)  # φ²: aggregation (e.g., 'add' = sum)\n",
    "\n",
    "        # φ: message MLP over (h_j, e_{j,i})\n",
    "        self.phi = nn.Sequential(\n",
    "            nn.Linear(in_channels + edge_dim, out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_channels, out_channels)\n",
    "        )\n",
    "\n",
    "        # α: update MLP over (h_i, aggregated_msg)\n",
    "        self.alpha = nn.Sequential(\n",
    "            nn.Linear(in_channels + out_channels, out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Optionally include self-loops; adapt edge_attr if needed\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        # Concatenate neighbor feature with edge attribute\n",
    "        msg_input = torch.cat([x_j, edge_attr], dim=-1)\n",
    "        return self.phi(msg_input)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # α(h_i, aggregated_messages)\n",
    "        update_input = torch.cat([x, aggr_out], dim=-1)\n",
    "        return self.alpha(update_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "id": "RRViActKE8e9"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "class RRMMP(gnn.MessagePassing):\n",
    "    def __init__(self,\n",
    "        alloc_dim: int, node_dim: int, edge_dim: int,\n",
    "        hidden_dim: int, aggr: str = \"sum\"\n",
    "    ):\n",
    "        super().__init__(aggr=aggr, node_dim = 0, flow = \"source_to_target\")  # φ²: aggregation (e.g., 'add' = sum)\n",
    "\n",
    "        in_dim = node_dim + edge_dim\n",
    "\n",
    "        # φ: message MLP over (h_j, e_{j,i})\n",
    "        self.phi1 = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim), nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        # α: update MLP over (h_i, aggregated_msg)\n",
    "        self.phi2 = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(), # maybe sigmoid\n",
    "        )\n",
    "\n",
    "        self.band_allocator = nn.Sequential(\n",
    "            nn.Linear(alloc_dim + hidden_dim, alloc_dim),\n",
    "            nn.Softmax(dim = 1)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x, v, edge_index, edge_attr):\n",
    "        # Optionally include self-loops; adapt edge_attr if needed\n",
    "        edge_index, edge_attr = add_self_loops(edge_index, edge_attr, num_nodes = x.size(0))\n",
    "\n",
    "        out = self.propagate(edge_index, x=x, v=v, edge_attr=edge_attr)\n",
    "        di = torch.cat([x, out], dim = 1)\n",
    "        return self.band_allocator(di)\n",
    "\n",
    "    def message(self, x_i, v_i, edge_attr):\n",
    "        # Concatenate neighbor feature with edge attribute\n",
    "        msg_input = torch.cat([v_i, edge_attr], dim=-1)\n",
    "        return self.phi1(msg_input)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # α(h_i, aggregated_messages)\n",
    "        return self.phi2(aggr_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gs0k5uapP1pR",
    "outputId": "4d9ec4ce-0eef-4fe3-f5cb-8f960179bde6"
   },
   "outputs": [],
   "source": [
    "tests_loader = DataLoader(CustomGraphDataset(tests_dataset, 20), batch_size = 64, shuffle=False)\n",
    "\n",
    "graph = next(iter(tests_loader))[1]\n",
    "print(graph)\n",
    "layer = RRMMP(4, 4, 4, 4)\n",
    "result = layer(graph.x, graph.v, graph.edge_index, graph.edge_attr)\n",
    "\n",
    "result[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "id": "KZefgE2ECg2z"
   },
   "outputs": [],
   "source": [
    "class GNNAllocator(nn.Module):\n",
    "    def __init__(self,\n",
    "        alloc_dim: int, node_dim: int, edge_dim: int, n_bands: int,\n",
    "        hidden_dim: int = 128, n_layers: int = 4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "        for _ in range(n_layers + 1):\n",
    "            l = RRMMP(alloc_dim, node_dim, edge_dim, hidden_dim)\n",
    "            layers.append((l, \"x, v, edge_index, edge_attr -> x\"))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        self.gnn = gnn.Sequential(\"x, v, edge_index, edge_attr\", layers[:-1])\n",
    "        self.n_bands = n_bands\n",
    "    def forward(self, data: Data | Batch, tau: float = 0.5):\n",
    "        x, v, edge_index, edge_attr = data.x, data.v, data.edge_index, data.edge_attr\n",
    "        x = self.gnn(x, v, edge_index, edge_attr)\n",
    "\n",
    "        # channel optimization\n",
    "\n",
    "        probs = x.reshape(data.batch_size, -1, self.n_bands)\n",
    "        probs = probs.permute(0, 2, 1)\n",
    "        return probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "id": "uH1JOtAw8pSh"
   },
   "outputs": [],
   "source": [
    "tests_loader = DataLoader(CustomGraphDataset(tests_dataset), batch_size = 64, shuffle=False)\n",
    "\n",
    "graph = next(iter(tests_loader))[1]\n",
    "print(graph)\n",
    "layer = GNNAllocator(4, 4, 4, 4)\n",
    "result = layer(graph)\n",
    "\n",
    "result[0, :, :4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "id": "21b55c6e"
   },
   "source": [
    "## Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "id": "sY-9VddeYhSj"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE   = 512\n",
    "REMOVE_EDGES = 100\n",
    "train_loader = DataLoader(CustomGraphDataset(train_dataset, REMOVE_EDGES), batch_size = BATCH_SIZE, shuffle=True )\n",
    "valid_loader = DataLoader(CustomGraphDataset(valid_dataset, REMOVE_EDGES), batch_size = BATCH_SIZE, shuffle=True )\n",
    "tests_loader = DataLoader(CustomGraphDataset(tests_dataset, REMOVE_EDGES), batch_size = BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "id": "AuNw8Mwxb03g"
   },
   "outputs": [],
   "source": [
    "def _bit_rate(config: SimConfig, C: torch.Tensor, A: torch.Tensor) -> torch.Tensor:\n",
    "    A    = torch.argmax(A, dim = 1)\n",
    "    sinr = rate_metrics.signal_interference_ratio(config, C, A, None)\n",
    "    rate = torch.sum( 10 * torch.log2(1 + sinr), dim = 1)\n",
    "    return torch.mean(rate, dim = 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "id": "rNeyBegWobji"
   },
   "outputs": [],
   "source": [
    "percentiles = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "836d5b6b44c74676b157e7e5dfc39d5c",
      "ab1ed33696d94a37b54b60db59ad42ed",
      "ae0b321d5ece4b548473ed94d26b169c",
      "a26e7d67f24c4944baeb203dd8dffd1b",
      "c3b43c209878428292863ed923fb732d",
      "8ea86d07a93f4c619361277cd38d1829",
      "4145e6528caf4315b32652bdefa2f1ee",
      "de0c9c8a0d9d4eaca11bb971f5fa9844",
      "94bcdf2ca38047f09a5e62437813020b",
      "081657b98e46444aa57c2d87d04c5486",
      "d2ae4a7119914cb7a91f63fce30ffa17",
      "3f38421e3ae848538a4b6b40ad989422",
      "f0d78e759f304797aca525b05258b68a",
      "ad7f5be4216146338006e4189031d55e",
      "4b33a9f2d6824bfb9b33c869fc4065a7",
      "8b9456220d624262a167ea02e8fff913",
      "86081bc8026b49c294e98e670cf57380",
      "821c5ff426b9463e991d4ba6faa268b8",
      "c175d1dcb7e1439a8bcd173a7aec8fb3",
      "1f6f09837f46454f851e3468eff43843",
      "7fbd78ce662b41d3b247e5fc1b4ee8d1",
      "c3530f3e753641c6b9f6922764536287",
      "397f234f7e2843aab1e7ea64f24871bb",
      "dfa260a8d63748418e729b0218d1c6b7",
      "3b6556c1cd534cffa827c6fde9af3557",
      "304e91d0a60d4bbdab8285abff8643e3",
      "63bb1ae4b3d84675a7465d3033db36bf",
      "78279cca3aeb4f7c929ee7929b793c6d",
      "38eb82c09c5548b7baa3e57a11733c1a",
      "cc10bb51f7984cbfa3e988e1b8ef65a8",
      "c2c3af89f48647849b61049540d954c9",
      "a14c338256e5467b93c5094d7e945a2e",
      "04ad2342d4da45bab8ad39212b376fea",
      "c98e04773c534d0cb2256c7dd7811220",
      "53451ddaa6fe4103996c71f365c104d5",
      "0e80c92426ac4395a80f99bd565b4983",
      "dc4bc437984a4cbf9736ded0a72c972f",
      "97236a9906cc48c083d16be57450beab",
      "8c8bf4b00da845c9884d07a6c8b2ac3c",
      "6e19351ab5874507b5bddbb9cf636dd1",
      "577ccefb0706439d96af30f81ab10c1c",
      "9e574a43ab1e4f419316977b63569ad2",
      "22a4c44b87604e6f9f26e76481c5df15",
      "bdfc49b62ab346268ee4203ebbc76b40",
      "d64188bd11834b2fba8e3c140646b30e",
      "4e6f1c09f3ad437baed15415f09b4ba8",
      "aceebaf2830f4c579e13037babcbe7be",
      "e45da67cca5244fda9d9922641a01754",
      "01bcf6b9da9a4564bc22f053802cc52b",
      "f14c8a7ac32e478abb84866c4743a57a",
      "5e522c535e60426fbd4faaab93f47cdb",
      "c922c3570dbe4b568256d3601d1b6929",
      "0f7d7cc71af843dfa2757561be96d277",
      "ef8f8bc296cd4e27b2cfc32fdd7eb1df",
      "4cab0373e05d4b7d87beed5ed9e005e9",
      "a9208fab1f3b49bc9c23d4d5f7823aea",
      "5cdea2cb63124723aa96101e89c4147f",
      "2f77e6cbbf084bedb38c9a7f64d9c288",
      "268349f797354dcbbd16562fa9b3dda2",
      "7dc7a98e96b341c69b999e3a972fcd7c",
      "e698d5938c2445ca9190fc7a6fccce3b",
      "b58528b5203d40699938698d38d1aa48",
      "0b0d5bdbebf6447b9bea161db8255e88",
      "6f310e67cfea4a79bcdad6eedb9ca242",
      "f783f31225ec4cb8b69d46817fc36720",
      "be334471138e4e63a1a86229bbcf0d9e",
      "f8605895c62440bfa163f1c1d1562e27",
      "1c8a2cb56df14a1db8365e7d108d3ce4",
      "cc55c56ffb324b1d9850599025d5ec1b",
      "f50159484cc64ae3bf5f7e926d2c5067",
      "3aea5de7bafe48ee8ac7d6b9e9e3a062",
      "7a9716e3d41a44809e82649df18fd1be",
      "e2e71874da86453dbdc87caa0331aa7c",
      "a03b4f149e5d443d8146525635c7742a",
      "107b35b8c5334caba3db08df66b0d6b3",
      "b12728477bb749eeaffb5fea2fdd66ab",
      "28fa0a7e164d4aa09356dec7c372ea7e"
     ]
    },
    "id": "2KOSDaLWYi-d",
    "outputId": "8009beb2-778e-4301-96cb-5ce4a6aca8ba"
   },
   "outputs": [],
   "source": [
    "model =  GNNAllocator(4, 4, 4, 4, 128, 4)\n",
    "model_name = f\"gnn-v3-{REMOVE_EDGES}\"\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0015)\n",
    "scheduler = lrs.CosineAnnealingLR(optimizer, T_max=40, eta_min=3e-4)\n",
    "\n",
    "loss_func = partial(loss_funcs.loss_pure_rate, mode = 'min', p = 1e5, a = 0.6)\n",
    "for step in range(5):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    total_bin_error = 0.\n",
    "    total_bit_rate  = 0.\n",
    "    for sample, graph in tqdm(train_loader, desc = \"training: \", unit=\" batch\", total = len(train_loader), leave = False):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        sample = sample.to(device)\n",
    "        graph  = graph.to(device)\n",
    "        alloc_prob = model(graph)        # soft output\n",
    "        loss = loss_func(config, sample, alloc_prob).mean()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # training metrics\n",
    "        total_loss += loss.item()\n",
    "        total_bin_error += loss_funcs.binarization_error(alloc_prob)\n",
    "        total_bit_rate  += _bit_rate(config, sample, alloc_prob)\n",
    "\n",
    "        del sample, alloc_prob, loss, graph\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    ttotal_loss = total_loss / len(train_loader)\n",
    "    ttotal_bin_error = total_bin_error / len(train_loader)\n",
    "    ttotal_bit_rate  = total_bit_rate / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    total_bin_error = 0.\n",
    "    total_bit_rate  = 0.\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sample, graph in tqdm(valid_loader, desc = \"validation: \", unit=\" batch\", total = len(valid_loader), leave = False):\n",
    "            sample = sample.to(device)\n",
    "            graph  = graph.to(device)\n",
    "            alloc_prob = model(graph)        # soft output\n",
    "            loss = loss_func(config, sample, alloc_prob).mean()\n",
    "\n",
    "            # loss = loss_interference(sample, alloc_prob).mean()\n",
    "            total_loss += loss.item()\n",
    "            total_bin_error += loss_funcs.binarization_error(alloc_prob)\n",
    "            total_bit_rate  += _bit_rate(config, sample, alloc_prob)\n",
    "\n",
    "            del sample, alloc_prob, loss, graph\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    total_loss = total_loss / len(valid_loader)\n",
    "    total_bin_error = total_bin_error / len(valid_loader)\n",
    "    total_bit_rate  = total_bit_rate / len(valid_loader)\n",
    "\n",
    "    lr = scheduler.get_last_lr()[-1]\n",
    "    print(\n",
    "        f\"[{step:>3d}] (lr: {lr:1.2e})\",\n",
    "        f\"train loss: {ttotal_loss:7.4f}\",\n",
    "        f\"(bin error: {ttotal_bin_error:5.3e}, bit rate: {ttotal_bit_rate:4.2f})\",\n",
    "        f\"valid loss: { total_loss:7.4f}\",\n",
    "        f\"(bin error: { total_bin_error:5.3e}, bit rate: { total_bit_rate:4.2f})\",\n",
    "        sep = \" \"\n",
    "    )\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "id": "6wMCeFylcJYD"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "model.eval()\n",
    "total_loss = 0.\n",
    "total_bin_error = 0.\n",
    "metrics = defaultdict(lambda : 0)\n",
    "\n",
    "rates = []\n",
    "with torch.no_grad():\n",
    "    for sample, graph in tqdm(tests_loader, desc = \"testing: \", unit=\" batch\", total = len(tests_loader), leave = False):\n",
    "        sample = sample.to(device)\n",
    "        graph  = graph.to(device)\n",
    "        A = model(graph)        # soft output\n",
    "        loss = loss_func(config, sample, A).mean()\n",
    "\n",
    "        # loss = loss_interference(sample, alloc_prob).mean()\n",
    "        total_loss += loss.item()\n",
    "        total_bin_error += loss_funcs.binarization_error(A)\n",
    "        total_bit_rate  += _bit_rate(config, sample, A)\n",
    "\n",
    "        A = torch.argmax(A, dim = 1)\n",
    "        metrics = loss_funcs.update_metrics(metrics, A, sample, None, config, 4)\n",
    "        sinr = rate_metrics.signal_interference_ratio(config, sample, A, None)\n",
    "        rate = torch.sum(10 * torch.log2(1 + sinr), dim = 1)\n",
    "        rates.append(rate.cpu().flatten().numpy())\n",
    "\n",
    "\n",
    "        del sample, A, loss, graph\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "total_loss = total_loss / len(tests_loader)\n",
    "total_bin_error = total_bin_error / len(tests_loader)\n",
    "\n",
    "metrics = { key: val / len(tests_loader) for key, val in metrics.items()}\n",
    "\n",
    "print(\"testing run:\")\n",
    "print(\"testing batches: \", len(tests_loader))\n",
    "print(\"test test error: \", total_loss)\n",
    "print(\"test test binarization error: \", total_bin_error)\n",
    "print(\"bit rate / quality metrics:\\n\", json.dumps(metrics, indent = 2))\n",
    "\n",
    "percentiles[model_name] = get_cdf(np.hstack(rates))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "id": "P0vewwCxsnEJ"
   },
   "source": [
    "# Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "id": "nsgGidzGslJU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "id": "I5cvMRBlot8b"
   },
   "outputs": [],
   "source": [
    "data = np.hstack(rates)\n",
    "for per in [0.005, 0.05, 0.5, 1, 10, 25, 50, 95, 99]:\n",
    "    per_point = np.percentile(data, per)\n",
    "    print(f\"percentile: {per:6.3f} ----> {per_point:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "id": "R8TKEXqQql9B"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.read_csv(\"./results.csv\", index_col = 0)\n",
    "\n",
    "for name, (pos, _) in percentiles.items():\n",
    "    results[f\"{name}_values\"] = pos\n",
    "\n",
    "display(results[ :20])\n",
    "display(results[-20:])\n",
    "\n",
    "_, ax = plt.subplots(1, 1, figsize = (6, 4))\n",
    "\n",
    "model_list = results.columns.tolist()[1:]\n",
    "\n",
    "for name in model_list:\n",
    "    per = results[\"percentiles\"].values\n",
    "    pos = results[name].values\n",
    "    ax.plot(pos, per, label = name)\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8hIVNP4fRfM",
    "outputId": "2796760f-a538-4835-f259-32a5431d6a0d"
   },
   "outputs": [],
   "source": [
    "results.to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "H, graph = next(iter(tests_loader))\n",
    "A = model(graph.to(device))\n",
    "\n",
    "A = torch.argmax(A, dim = 1)\n",
    "A = rate_metrics.onehot_allocation(A, 4, 20)\n",
    "\n",
    "H  = H.to(device)\n",
    "Ar = A.unsqueeze(2)\n",
    "Ac = A.unsqueeze(3)\n",
    "\n",
    "interference = torch.matmul(H , Ac)\n",
    "interference = torch.matmul(Ar, interference)\n",
    "interference.sum(dim = (1, 2, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "di = torch.arange(20)\n",
    "sample[:, :, di, di].shape\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
