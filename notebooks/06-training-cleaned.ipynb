{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0",
    "outputId": "fbada3c0-f36e-4946-bd12-ec5acfe36f28"
   },
   "outputs": [],
   "source": [
    "COLAB: bool = False\n",
    "if COLAB:\n",
    "  !git clone https://github.com/RubenCid35/6GSmartRRM\n",
    "  !mv 6GSmartRRM/* /content/\n",
    "  !pip install -e .\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi -q | grep 'Power Limit' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!cd .. && pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "1"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "!pip install -q wandb matplotlib seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 662
    },
    "id": "2",
    "outputId": "3b32ddc3-0694-42a3-cd98-36792fdb39b6"
   },
   "outputs": [],
   "source": [
    "# simple data manipulation\n",
    "import numpy  as np\n",
    "\n",
    "# deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lrs\n",
    "from   torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch.cuda.amp as amp # For Automatic Mixed Precision\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# progress bar\n",
    "from   tqdm.notebook import tqdm, trange\n",
    "import wandb\n",
    "\n",
    "# remove warnings (remove deprecated warnings)\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# visualization of resultsa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from   matplotlib.ticker import MaxNLocator\n",
    "import seaborn           as sns\n",
    "\n",
    "# wheter we are using colab or not\n",
    "import os\n",
    "if not COLAB and not os.path.exists('./data/simulations'):\n",
    "    os.chdir('..')\n",
    "    print(\"current path: \", os.getcwd())\n",
    "\n",
    "# Simulation Settings\n",
    "from g6smart.sim_config import SimConfig\n",
    "from g6smart.evaluation import rate as rate\n",
    "from g6smart.evaluation.utils import get_cdf\n",
    "from g6smart.evaluation import rate_torch as rate_metrics\n",
    "from g6smart.proposals  import loss as loss_funcs, rate_cnn, rate_dnn\n",
    "from g6smart.data import load_data, create_datasets, download_simulations_data\n",
    "from g6smart.track import setup_wandb, real_time_plot\n",
    "\n",
    "config = SimConfig(0)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "id": "4"
   },
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3",
    "outputId": "bc483418-e4f4-4c78-9fc3-115582b39ddf"
   },
   "outputs": [],
   "source": [
    "simulation_path, models_path = download_simulations_data(COLAB)\n",
    "print(\"simulations data paths:\", simulation_path)\n",
    "print(\"saved model location  :\", models_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "id": "7a5722d6"
   },
   "outputs": [],
   "source": [
    "csi_data = load_data(simulation_path, n_samples=120_000)\n",
    "train_dataset, valid_dataset, tests_dataset = create_datasets(\n",
    "#    csi_data, split_sizes=[130_000, 60_000, 10_000], batch_size=2048, seed=101\n",
    "    csi_data, split_sizes=[ 70_000, 30_000, 20_000], batch_size= 1024, seed=101\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=2048, shuffle=True )\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=2048, shuffle=True )\n",
    "tests_loader = DataLoader(tests_dataset, batch_size=2048, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "id": "Htb2if05QdhF"
   },
   "source": [
    "## FNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "id": "6"
   },
   "source": [
    "## FNN Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "id": "TRNNqFhl8Llv"
   },
   "outputs": [],
   "source": [
    "def min_approx(x: torch.Tensor, p: float = 1e8, mu: float = 0.):\n",
    "    \"\"\"\n",
    "    Differentiable Approximation of Minimum Function. This function approximates\n",
    "    the value of min(x)\n",
    "\n",
    "      # based on fC https://mathoverflow.net/questions/35191/a-differentiable-approximation-to-the-minimum-function\n",
    "    \"\"\"\n",
    "    return mu - (1 / p) * torch.logsumexp(-p * (x - mu), dim = 1)\n",
    "\n",
    "def loss_pure_rate(\n",
    "  config: SimConfig, C: torch.Tensor, A: torch.Tensor,\n",
    "  mode: str = 'sum', p: int = 1e8, a: float = 0.5\n",
    ") -> torch.Tensor:\n",
    "    sinr = rate_metrics.signal_interference_ratio(config, C, A, None)\n",
    "    mask = torch.sigmoid(10 * (sinr - 0.01))\n",
    "    rate = torch.sum(torch.log2(1 + sinr) * A * mask, dim = 1)\n",
    "    rate = rate / torch.sum(A, dim = 1)\n",
    "\n",
    "    if mode == 'sum':\n",
    "      loss_rate = torch.sum(rate, dim = 1)\n",
    "    elif mode == 'min':\n",
    "      loss_rate = min_approx(rate, p)\n",
    "    elif mode == 'max':\n",
    "      loss_rate = torch.sum(rate, dim = 1)\n",
    "    elif mode == \"mean\":\n",
    "      loss_rate = torch.mean(rate, dim = 1)\n",
    "    elif mode == \"hybrid\":\n",
    "      loss_rate = a * torch.mean(rate, dim = 1) + (1 - a) * min_approx(rate, p)\n",
    "    return - loss_rate\n",
    "\n",
    "def loss_interference(C: torch.Tensor, A: torch.Tensor):\n",
    "  losses = A.unsqueeze(-1) * 10 * torch.log10(C + 1e-12) * A.unsqueeze(-2)\n",
    "  # losses = 10 * torch.log10(losses + 1e-12)\n",
    "  return torch.sum(losses.flatten(start_dim = 1), dim = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T0slfIVWCV_A",
    "outputId": "10919a49-d919-43c2-ff3e-e9553a0d8967"
   },
   "outputs": [],
   "source": [
    "sample = torch.rand(256, 100000)\n",
    "mint = torch.max(sample, dim = 1)[0]\n",
    "for p in range(-2, 10):\n",
    "  min1 = loss_funcs.min_approx(sample, p = - 10 ** p)\n",
    "  min2 = min_approx(sample, p = - 10 ** p)\n",
    "  dis1 = torch.abs(min1 - mint).mean().item()\n",
    "  dis2 = torch.abs(min2 - mint).mean().item()\n",
    "  print(f\"{10 ** p:3.2e} -> min (lib): {dis1:7.6e}\\tmin (new): {dis2:7.6e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "id": "y_z2m7YiQgKB"
   },
   "outputs": [],
   "source": [
    "class FNNModel(nn.Module):\n",
    "  def __init__(\n",
    "      self, N: int, K: int,\n",
    "      hidden_dim: int = 1024, hidden_layers: int = 4,\n",
    "      dropout: float = 1e-1, to_matrix: bool = False\n",
    "  ):\n",
    "    super().__init__()\n",
    "    self.N = N\n",
    "    self.K = K\n",
    "\n",
    "    self.triu_mask = torch.triu(\n",
    "        torch.ones(self.N, self.N, dtype = torch.bool),\n",
    "        diagonal = 1\n",
    "    )\n",
    "    self.to_matrix = to_matrix\n",
    "    if self.to_matrix:\n",
    "      self.in_size  = self.N * (self.N - 1) // 2\n",
    "    else:\n",
    "      self.in_size  = self.N * (self.N - 1) // 2 * self.K\n",
    "\n",
    "    self.out_size = self.K * self.N\n",
    "\n",
    "    layers = [ ]\n",
    "    #nn.BatchNorm1d(self.in_size),\n",
    "    #nn.BatchNorm2d(self.K), nn.Flatten()\n",
    "\n",
    "    dims = [self.in_size] + [hidden_dim] * (hidden_layers + 1) + [self.out_size]\n",
    "\n",
    "    for _in, _out in zip(dims[:-1], dims[1:]):\n",
    "      layers.append(nn.Linear(_in, _out))\n",
    "      torch.nn.init.kaiming_normal_(layers[-1].weight, nonlinearity='relu')\n",
    "      layers.append(nn.ReLU())\n",
    "      layers.append(nn.BatchNorm1d(_out))\n",
    "      layers.append(nn.Dropout(dropout))\n",
    "\n",
    "    self.model = nn.Sequential(*layers[:-3])\n",
    "\n",
    "  def preprocess(self, H: torch.Tensor) -> torch.Tensor:\n",
    "    shape = 'x'.join(map(str, H.shape[1:]))\n",
    "    assert len(H.shape)  == 4 and H.size(1) == self.K and H.size(2) == self.N and H.size(3) == self.N, (\n",
    "        f\"The input tensor needs to match Bx{self.K}x{self.N}x{self.N}, not Bx{shape} (B is the batch size)\"\n",
    "    )\n",
    "\n",
    "    # take only the upper triangle\n",
    "    if self.to_matrix:\n",
    "      H = torch.sum(H, dim = 1)\n",
    "      H = H[:, self.triu_mask]\n",
    "    else:\n",
    "      Hd = torch.diagonal(H, dim1=2, dim2=3).unsqueeze(-1)\n",
    "      H  = H / Hd\n",
    "      H  = H[:, :, self.triu_mask] # B x K x (N * (N - 1) // 2)\n",
    "\n",
    "\n",
    "    # reshape\n",
    "    H = 10 * torch.log10(H + 1e-12)\n",
    "\n",
    "    # could this be learned\n",
    "    mean = torch.mean(H, dim = 1, keepdim=True)\n",
    "    std  = torch.std( H, dim = 1, keepdim=True)\n",
    "    H    = (H - mean) / (std + 1e-8)\n",
    "    return H\n",
    "\n",
    "  def forward(self, H: torch.Tensor) -> torch.Tensor:\n",
    "    H = self.preprocess(H)\n",
    "    x = self.model(H)\n",
    "    x = x.reshape(-1, self.K, self.N)\n",
    "    return F.softmax(x, dim = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "id": "mg1FRAjrlG6w"
   },
   "source": [
    "# CNN + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PPt-hUb6lJID",
    "outputId": "3f5ebfdf-8446-4d71-ce44-50657b943479"
   },
   "outputs": [],
   "source": [
    "class CLAllocator(nn.Module):\n",
    "  def __init__(\n",
    "    self, n_subnetworks: int, n_subbands: int,\n",
    "    feature_dim: int = 64, hidden_dim: int = 128\n",
    "  ):\n",
    "    super().__init__()\n",
    "    assert n_subbands >= 4, \"the model config only works with at least 4 bands\"\n",
    "    assert n_subnetworks >= 4, \"the model config only works with at least 4 bands\"\n",
    "\n",
    "    self.N = n_subnetworks\n",
    "    self.K = n_subbands\n",
    "\n",
    "    self.feature_dim = feature_dim\n",
    "    self.hidden_dim  = hidden_dim\n",
    "\n",
    "    self.encoder = nn.Sequential(\n",
    "        nn.Conv2d(1, 32, kernel_size=(3, 3), padding=1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(), # GELU generally performs well, keep unless direct performance hit\n",
    "        nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "\n",
    "        nn.Conv2d(32, 64, kernel_size=(3, 3), padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "\n",
    "        nn.Conv2d(64, self.feature_dim, kernel_size=(3, 3), padding=1),\n",
    "        nn.BatchNorm2d(self.feature_dim),\n",
    "        nn.ReLU(),\n",
    "\n",
    "        nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        nn.Flatten(),\n",
    "    )\n",
    "\n",
    "    self.lstm = nn.LSTM(\n",
    "        input_size    = self.feature_dim,\n",
    "        hidden_size   = self.hidden_dim,\n",
    "        num_layers    = 2,\n",
    "        batch_first   = True,\n",
    "        bidirectional = True # Keep bidirectional for potential performance unless proven slower\n",
    "    )\n",
    "\n",
    "    lstm_output_dim = self.hidden_dim * 2 if self.lstm.bidirectional else self.hidden_dim\n",
    "\n",
    "    self.allocator = nn.Sequential(\n",
    "        nn.Linear(lstm_output_dim, self.hidden_dim * 2),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(self.hidden_dim * 2),\n",
    "        nn.Dropout(p = 0.2),\n",
    "\n",
    "        nn.Linear(self.hidden_dim * 2, self.hidden_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(self.hidden_dim),\n",
    "        nn.Dropout(p = 0.2),\n",
    "\n",
    "        nn.Linear(self.hidden_dim, self.K),\n",
    "        nn.Softmax(dim = 1) # Keep Softmax only if loss_pure_rate expects probabilities, not logits\n",
    "    )\n",
    "\n",
    "\n",
    "  def preprocess(self, H: torch.Tensor) -> torch.Tensor:\n",
    "    Hdb = 10 * torch.log10(H + 1e-12)\n",
    "    mean, std = -73, -10 # empirical metrics\n",
    "    return (Hdb - mean) / std\n",
    "\n",
    "\n",
    "  def forward(self, H: torch.Tensor) -> torch.Tensor:\n",
    "    batch_size = H.shape[0]\n",
    "    H = self.preprocess(H)\n",
    "    H_reshaped_for_encoder = H.permute(0, 2, 1, 3).reshape(batch_size * self.N, self.K, self.N).unsqueeze(1)\n",
    "\n",
    "    all_encodings = self.encoder(H_reshaped_for_encoder)\n",
    "    encodings = all_encodings.reshape(batch_size, self.N, self.feature_dim)\n",
    "\n",
    "    lstm_output, _ = self.lstm(encodings)\n",
    "\n",
    "    lstm_output_reshaped = lstm_output.reshape(-1, lstm_output.shape[-1])\n",
    "    all_probs = self.allocator(lstm_output_reshaped)\n",
    "\n",
    "    probs = all_probs.reshape(batch_size, self.N, self.K)\n",
    "    probs = probs.permute(0, 2, 1)\n",
    "    return probs\n",
    "\n",
    "K, N = 4, 20\n",
    "sample = torch.rand(2, K, N, N)\n",
    "model  = CLAllocator(N, K)\n",
    "model(sample).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMAllocator(nn.Module):\n",
    "  def __init__(\n",
    "    self, n_subnetworks: int, n_subbands: int,\n",
    "    hidden_dim: int = 128, lstm_layers: int = 3,\n",
    "  ):\n",
    "    super().__init__()\n",
    "    assert n_subbands >= 4, \"the model config only works with at least 4 bands\"\n",
    "    assert n_subnetworks >= 4, \"the model config only works with at least 4 bands\"\n",
    "\n",
    "    self.N = n_subnetworks\n",
    "    self.K = n_subbands\n",
    "\n",
    "    self.hidden_dim  = hidden_dim\n",
    "    self.feature_dim = self.N * self.K\n",
    "      \n",
    "    self.lstm = nn.LSTM(\n",
    "        input_size    = self.feature_dim,\n",
    "        hidden_size   = self.hidden_dim,\n",
    "        num_layers    = lstm_layers,\n",
    "        batch_first   = True,\n",
    "        bidirectional = True # Keep bidirectional for potential performance unless proven slower\n",
    "    )\n",
    "\n",
    "    lstm_output_dim = self.hidden_dim * 2 if self.lstm.bidirectional else self.hidden_dim\n",
    "\n",
    "    self.allocator = nn.Sequential(\n",
    "        nn.Linear(lstm_output_dim, self.hidden_dim * 2),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(self.hidden_dim * 2),\n",
    "        nn.Dropout(p = 0.2),\n",
    "\n",
    "        nn.Linear(self.hidden_dim * 2, self.hidden_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(self.hidden_dim),\n",
    "        nn.Dropout(p = 0.2),\n",
    "\n",
    "        nn.Linear(self.hidden_dim, self.K),\n",
    "        nn.Softmax(dim = 1) # Keep Softmax only if loss_pure_rate expects probabilities, not logits\n",
    "    )\n",
    "\n",
    "  def forward(self, H: torch.Tensor) -> torch.Tensor:\n",
    "    batch_size = H.size(0)\n",
    "\n",
    "    network_vector = H.permute(0, 2, 1, 3)\n",
    "    network_vector = network_vector.flatten(start_dim = 2)\n",
    "    lstm_output, _ = self.lstm(network_vector)\n",
    "\n",
    "    lstm_output_reshaped = lstm_output.reshape(-1, lstm_output.shape[-1])\n",
    "    all_probs = self.allocator(lstm_output_reshaped)\n",
    "\n",
    "    probs = all_probs.reshape(batch_size, self.N, self.K)\n",
    "    probs = probs.permute(0, 2, 1)\n",
    "    return probs\n",
    "\n",
    "K, N = 4, 20\n",
    "sample = torch.rand(2, K, N, N)\n",
    "model  = LSTMAllocator(N, K)\n",
    "model(sample).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "EmaW7q2Vdir3",
    "outputId": "47c3e98c-1b4c-4dbd-96fd-3f69eceb00ff"
   },
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "id": "XiNBp4zYNtsp"
   },
   "outputs": [],
   "source": [
    "percentiles = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "c9e5abdbc4444113a9032b49e5fc8c4f",
      "f3f43d9367e14d30a294eb447228651d",
      "68b9b4d0ab3e4cafbd33766ba24c400b",
      "eb02ec8a081b4046a88574ce566c0b02",
      "b467ffaff42843ee89084f1961a96189",
      "8c44d9d25e95492abfdd82e72c901ac7",
      "e3b300c7eb354a94a1da305fcef69add",
      "d7ec2a0ecc7f4e039fed3de7420706b6",
      "3b57019e3c094286b0727b30d0854cf2",
      "5b26ca4ced604e9e93fb116deda26c12",
      "e12982c6559e429bbbf90c738f45877b"
     ]
    },
    "id": "4YRTuSpMBUZd",
    "outputId": "7b328d91-4620-46c8-ce92-b67eff3e4901"
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "del model\n",
    "model = CLAllocator(20, 4, 256, 512)\n",
    "model = LSTMAllocator(20, 4, 512, 4)\n",
    "#model = FNNModel(20, 4, 512, 3, 0.1, True) # .to(device)\n",
    "#model = rate_cnn.RateConfirmAllocCNNModel(20, 4, 0.1, True)\n",
    "\n",
    "train_model(model, config, train_loader, valid_loader, )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "id": "zhbkE8mcoHTk"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "model.eval()\n",
    "total_loss = 0.\n",
    "total_bin_error = 0.\n",
    "metrics = defaultdict(lambda : 0)\n",
    "\n",
    "rates = []\n",
    "with torch.no_grad():\n",
    "  for sample in tqdm(tests_loader, desc = \"testing: \", unit=\" batch\", total = len(tests_loader), leave = False):\n",
    "    sample = sample[0].to(device)\n",
    "    A = model(sample)        # soft output\n",
    "    loss = loss_pure_rate(config, sample, A,  'min', p = 1e6).mean()\n",
    "    # loss = loss_interference(sample, alloc_prob).mean()\n",
    "    total_loss += loss.item()\n",
    "    total_bin_error += loss_funcs.binarization_error(A)\n",
    "\n",
    "    metrics = loss_funcs.update_metrics(metrics, A, sample, None, config, 4)\n",
    "\n",
    "    A    = torch.argmax(A, dim = 1)\n",
    "    sinr = rate_metrics.signal_interference_ratio(config, sample, A, None)\n",
    "    rate = torch.sum(10 * torch.log2(1 + sinr), dim = 1)\n",
    "    rates.append(rate.cpu().flatten().numpy())\n",
    "\n",
    "    del sample, A, loss\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "total_loss = total_loss / len(tests_loader)\n",
    "total_bin_error = total_bin_error / len(tests_loader)\n",
    "\n",
    "metrics = { key: val / len(tests_loader) for key, val in metrics.items()}\n",
    "\n",
    "print(\"testing run:\")\n",
    "print(\"testing batches: \", len(tests_loader))\n",
    "print(\"test test error: \", total_loss)\n",
    "print(\"test test binarization error: \", total_bin_error)\n",
    "print(\"bit rate / quality metrics:\\n\", json.dumps(metrics, indent = 2))\n",
    "\n",
    "percentiles[model_name] = get_cdf(np.hstack(rates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.hstack(rates)\n",
    "np.percentile(data, 0.05), np.median(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "id": "Cz4_nr-pKB1s"
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 1, figsize = (8, 8))\n",
    "for name, (pos, per) in percentiles.items():\n",
    "  ax.plot(pos, per, label = name)\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"percentiles\": per }\n",
    "data.update( { \n",
    "    f\"{name}_values\" : pos for name, (pos, _) in percentiles.items() \n",
    "})\n",
    "print(data.columns)\n",
    "pd.DataFrame(data).to_csv(\"../results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "rrm-g6-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
