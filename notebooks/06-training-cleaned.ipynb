{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB: bool = False\n",
    "if COLAB:\n",
    "  %git clone https://github.com/RubenCid35/6GSmartRRM\n",
    "  %mv 6GSmartRRM/* .\n",
    "  %pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple data manipulation\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "# deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lrs\n",
    "from   torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# progress bar\n",
    "from   tqdm.notebook import tqdm, trange\n",
    "import wandb\n",
    "# remove warnings (remove deprecated warnings)\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# visualization of resultsa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from   matplotlib.ticker import MaxNLocator\n",
    "import seaborn           as sns\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "# wheter we are using colab or not\n",
    "import os\n",
    "if not COLAB and not os.path.exists('./data/simulations'):\n",
    "    os.chdir('..')\n",
    "\n",
    "# Simulation Settings\n",
    "from g6smart.sim_config import SimConfig\n",
    "from g6smart.evaluation import rate as rate\n",
    "from g6smart.evaluation import rate_torch as rate_metrics\n",
    "from g6smart.proposals  import loss as loss_funcs, rate_cnn, rate_dnn\n",
    "from g6smart.data import load_data, create_datasets, download_simulations_data\n",
    "from g6smart.track import setup_wandb, real_time_plot\n",
    "\n",
    "config = SimConfig(0)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_path, models_path = download_simulations_data(COLAB)\n",
    "csi_data = load_data(simulation_path, n_samples=60_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, tests_loader = create_datasets(\n",
    "    csi_data, split_sizes=[40_000, 10_000, 10_000], batch_size=128, seed=101\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## FNN Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE: int = 128\n",
    "MAX_EPOCH : int = 40\n",
    "LR: float  = 3e-4\n",
    "\n",
    "# under ideal conditions, the sisa ideal shannon rate is around 4.\n",
    "REQ: float      = 8.\n",
    "\n",
    "learning_config = {\n",
    "    'loss': 'pure-min-rate',\n",
    "    'max-epoch': MAX_EPOCH,\n",
    "    'batch-size': BATCH_SIZE,\n",
    "    'learning-rate': LR,\n",
    "    'desired-norm-rate' : REQ,\n",
    "}\n",
    "\n",
    "# training config\n",
    "HS: int    = 1024\n",
    "HL: int    = 6\n",
    "DP: float  = 0.1\n",
    "KEEP_BANDS: bool = True\n",
    "WEIGHTED_GAIN: bool = True\n",
    "\n",
    "model_config = {\n",
    "    'dropout': DP,\n",
    "    'weighted-gain': WEIGHTED_GAIN,\n",
    "}\n",
    "\n",
    "name  = \"p3-fnn-00-01-base\"\n",
    "training_config = {}\n",
    "training_config.update(model_config)\n",
    "training_config.update(learning_config)\n",
    "\n",
    "run = setup_wandb(name, 'cnn-rate-confirming', training_config, id = None)\n",
    "print(\"run config:\", run.config)\n",
    "\n",
    "model = rate_dnn.RateConfirmAllocModel(20, 4, HS, HL, DP, True, True).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), LR, weight_decay=1e-5)\n",
    "scheduler = lrs.CosineAnnealingLR(optimizer, T_max=25, eta_min=1e-4)\n",
    "train_loss, valid_loss, train_rate, valid_rate = [], [], [], []\n",
    "for epoch in trange(MAX_EPOCH, desc = \"training epoch\", unit = \"epoch\"):\n",
    "    real_time_plot(train_loss, valid_loss, train_rate, valid_rate)\n",
    "\n",
    "    # training step\n",
    "    model.train()\n",
    "    training_loss = 0.\n",
    "    train_binary_loss = 0.\n",
    "\n",
    "    temp = 1.0 # temp_scheduler.step()\n",
    "    training_metrics = defaultdict(lambda : 0)\n",
    "    for sample in tqdm(train_loader, desc = 'training step:', unit = 'batch', total = len(train_loader), leave=False):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        sample     = sample[0].to(device)\n",
    "        alloc_prob = model(sample, temp)\n",
    "        loss       = loss_funcs.loss_pure_rate(config, sample, alloc_prob, None, 'min').mean()\n",
    "        # loss       = loss_fullfield_req(config, sample, alloc_prob, REQ).mean()\n",
    "        training_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_binary_loss += loss_funcs.binarization_error(alloc_prob).item()\n",
    "        training_metrics = loss_funcs.update_metrics(training_metrics, alloc_prob, sample, None, config, REQ)\n",
    "\n",
    "    scheduler.step()\n",
    "    training_loss = training_loss / len(train_loader)\n",
    "    train_binary_loss = train_binary_loss / len(train_loader)\n",
    "    training_metrics = { 'train-' + key: val / len(train_loader) for key, val in training_metrics.items()}\n",
    "\n",
    "    model.eval()\n",
    "    validation_loss = 0.\n",
    "    valid_binary_loss = 0.\n",
    "    validation_metrics = defaultdict(lambda : 0.)\n",
    "    for sample in tqdm(valid_loader, desc = 'validation step:', unit = 'batch', total = len(valid_loader), leave = False):\n",
    "        sample     = sample[0].to(device)\n",
    "        alloc_prob = model(sample, temp)\n",
    "        loss       = loss_funcs.loss_pure_rate(config, sample, alloc_prob, None, 'min').mean()\n",
    "        # loss       = loss_fullfield_req(config, sample, alloc_prob, REQ).mean()\n",
    "        validation_loss += loss.item()\n",
    "\n",
    "        valid_binary_loss += loss_funcs.binarization_error(alloc_prob).item()\n",
    "        validation_metrics = loss_funcs.update_metrics(validation_metrics, alloc_prob, sample, None, config, REQ)\n",
    "\n",
    "    validation_loss = validation_loss / len(valid_loader)\n",
    "    valid_binary_loss = valid_binary_loss / len(valid_loader)\n",
    "\n",
    "    validation_metrics = { 'valid-' + key: val / len(valid_loader) for key, val in validation_metrics.items()}\n",
    "\n",
    "    logged_values = {\n",
    "        'train-loss': training_loss, 'valid-loss': validation_loss, 'temperature': temp,\n",
    "        'train-binary-loss': train_binary_loss, 'valid-binary-loss': valid_binary_loss\n",
    "    }\n",
    "\n",
    "    logged_values.update(training_metrics)\n",
    "    logged_values.update(validation_metrics)\n",
    "\n",
    "    train_loss.append(training_loss)\n",
    "    valid_loss.append(validation_loss)\n",
    "    train_rate.append(training_metrics['train-bit-rate'])\n",
    "    valid_rate.append(validation_metrics['valid-bit-rate'])\n",
    "    wandb.log(logged_values)\n",
    "\n",
    "wandb.finish()\n",
    "torch.save(model.state_dict(), os.path.join(models_path, \"cnn-min-00-01.pt\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rrm-g6-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
