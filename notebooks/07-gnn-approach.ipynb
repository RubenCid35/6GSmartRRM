{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB: bool = False\n",
    "if COLAB:\n",
    "  !git clone https://github.com/RubenCid35/6GSmartRRM\n",
    "  !mv 6GSmartRRM/* /content/\n",
    "  !pip install -e .\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vast ai check gpu for invalid specs\n",
    "!nvidia-smi -q | grep 'Power Limit' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "!pip install -q wandb matplotlib seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple data manipulation\n",
    "import numpy  as np\n",
    "\n",
    "# deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lrs\n",
    "from   torch.utils.data import DataLoader\n",
    "import torch.cuda.amp as amp # For Automatic Mixed Precision\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# progress bar\n",
    "from   tqdm.notebook import tqdm, trange\n",
    "import wandb\n",
    "\n",
    "# remove warnings (remove deprecated warnings)\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# visualization of resultsa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from   matplotlib.ticker import MaxNLocator\n",
    "import seaborn           as sns\n",
    "\n",
    "# wheter we are using colab or not\n",
    "import os\n",
    "if not COLAB and not os.path.exists('./data/simulations'):\n",
    "    os.chdir('..')\n",
    "    print(\"current path: \", os.getcwd())\n",
    "\n",
    "# Simulation Settings\n",
    "from g6smart.sim_config import SimConfig\n",
    "from g6smart.evaluation import rate as rate\n",
    "from g6smart.evaluation.utils import get_cdf\n",
    "from g6smart.evaluation import rate_torch as rate_metrics\n",
    "from g6smart.proposals  import loss as loss_funcs, rate_cnn, rate_dnn\n",
    "from g6smart.data import load_data, create_datasets, download_simulations_data\n",
    "from g6smart.track import setup_wandb, real_time_plot\n",
    "from g6smart.train import train_model\n",
    "\n",
    "config = SimConfig(0)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_path, models_path = download_simulations_data(COLAB)\n",
    "print(\"simulations data paths:\", simulation_path)\n",
    "print(\"saved model location  :\", models_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "csi_data = load_data(simulation_path, n_samples=12_000)\n",
    "train_dataset, valid_dataset, tests_dataset = create_datasets(\n",
    "#    csi_data, split_sizes=[130_000, 60_000, 10_000], batch_size=2048, seed=101\n",
    "    csi_data, split_sizes=[ 7_000, 3_000, 2_000], seed=101\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Graph Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Data, Dataset as GeoDataset\n",
    "\n",
    "class CustomGraphDataset(GeoDataset):\n",
    "    def __init__(self, torch_dataset: Dataset):\n",
    "        super().__init__(None, None)\n",
    "        self.torch_dataset = torch_dataset\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self): return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self): return []\n",
    "\n",
    "    def len(self) -> int: return len(self.torch_dataset)\n",
    "    def __len__(self) -> int: return len(self.torch_dataset)\n",
    "\n",
    "    def get(self, idx: int) -> Data:\n",
    "        # get raw data\n",
    "        csi_tensor = self.torch_dataset[idx][0]\n",
    "        K, N, _ = csi_tensor.shape\n",
    "\n",
    "        # node features\n",
    "        node_attr= torch.randn(N, 16) # node features\n",
    "        \n",
    "        # edage features\n",
    "        row, col    = torch.combinations(torch.arange(N), 2).t()\n",
    "        cell_coords = torch.stack([row, col])\n",
    "        edge_index  = torch.cat([cell_coords, cell_coords], dim = 1)\n",
    "        edge_attr = csi_tensor[:, row, col].permute(1, 0)\n",
    "        edge_attr = torch.cat([edge_attr, edge_attr], dim = 0)\n",
    "        \n",
    "        return Data(x = node_attr, edge_index = edge_index, edge_attr = edge_attr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader # Import PyG DataLoader\n",
    "\n",
    "BATCH_SIZE   = 1024\n",
    "train_loader = DataLoader(CustomGraphDataset(train_dataset), batch_size = BATCH_SIZE, shuffle=True )\n",
    "valid_loader = DataLoader(CustomGraphDataset(valid_dataset), batch_size = BATCH_SIZE, shuffle=True )\n",
    "tests_loader = DataLoader(CustomGraphDataset(tests_dataset), batch_size = BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Graph Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.nn as gnn\n",
    "\n",
    "class CustomMessagePassing(gnn.MessagePassing):\n",
    "    def __init__(self, node_dim: int, edge_dim: int, out_dim: int, **kwargs):\n",
    "        super().__init__(aggr='add', flow='source_to_target', **kwargs)\n",
    "\n",
    "        self.msg_mlp = nn.Sequential(\n",
    "            nn.Linear(node_dim + edge_dim, out_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(out_dim),\n",
    "            nn.Linear(out_dim, out_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.upt_mlp = nn.Sequential(\n",
    "            nn.Linear(node_dim + out_dim, out_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(out_dim),\n",
    "            nn.Linear(out_dim, out_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        return self.propagate(edge_index=edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        combined = torch.cat([x_j, edge_attr], dim=-1)\n",
    "        return self.msg_mlp(combined)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        combined = torch.cat([aggr_out, x], dim=-1)\n",
    "        return self.upt_mlp(combined)\n",
    "    \n",
    "class GNNAllocator(nn.Module):\n",
    "    def __init__(self, n_subbands: int, node_dim: int, edge_dim: int, hidden_dim: int = 128, gnn_layers: int = 3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.K = n_subbands\n",
    "        self.node_embed = nn.Linear(node_dim, hidden_dim)\n",
    "\n",
    "        gnn_blocks = []\n",
    "        for _ in range(gnn_layers):\n",
    "            gnn_blocks.append(\n",
    "                (CustomMessagePassing(hidden_dim, edge_dim, hidden_dim), 'x, edge_index, edge_attr -> x')\n",
    "            )\n",
    "\n",
    "        self.gnn_layers = gnn.Sequential('x, edge_index, edge_attr', gnn_blocks)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim // 2, self.K),\n",
    "            nn.Softmax(dim = 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = self.node_embed(x)\n",
    "        x = self.gnn_layers(x, edge_index, edge_attr)\n",
    "        return self.classifier(x)\n",
    "    \n",
    "model = GNNAllocator(4, 16, 4)\n",
    "data = next(iter(train_loader))\n",
    "print(model)\n",
    "model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import NNConv\n",
    "\n",
    "class SubbandAllocatorGNN(torch.nn.Module):\n",
    "    def __init__(self, node_feat_dim, edge_feat_dim, hidden_dim, num_classes):\n",
    "        super(SubbandAllocatorGNN, self).__init__()\n",
    "\n",
    "        # MLP to process edge features into dynamic weight matrices\n",
    "        self.edge_mlp1 = nn.Sequential(\n",
    "            nn.Linear(edge_feat_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim * node_feat_dim)\n",
    "        )\n",
    "\n",
    "        self.conv1 = NNConv(\n",
    "            in_channels=node_feat_dim,\n",
    "            out_channels=hidden_dim,\n",
    "            nn=self.edge_mlp1,\n",
    "            aggr='mean'\n",
    "        )\n",
    "\n",
    "        self.edge_mlp2 = nn.Sequential(\n",
    "            nn.Linear(edge_feat_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim * hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.conv2 = NNConv(\n",
    "            in_channels=hidden_dim,\n",
    "            out_channels=hidden_dim,\n",
    "            nn=self.edge_mlp2,\n",
    "            aggr='mean'\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, num_classes),\n",
    "            nn.Softmax(dim = 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, data: Data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        # x: [N, node_feat_dim]\n",
    "        # edge_index: [2, E]\n",
    "        # edge_attr: [E, edge_feat_dim]\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_attr))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model2 = SubbandAllocatorGNN(16, 4, 64, 4)\n",
    "model2(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_size = 0\n",
    "for param in model2.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in model2.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Training Procedure"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rrm-g6-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
